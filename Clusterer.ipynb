{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "79d8651b-5274-4fc6-ab22-176f456fa406",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Evolution including Virus Family hybrid Clustering based on artificially mutated K-mers\n",
    "\n",
    "## Milestones\n",
    "\n",
    "- [x] HDBSCAN github errors\n",
    "    - need to find version without problems\n",
    "    - if now finding one revert back to MA version\n",
    "    - revert back to Masterthesis and update jupyter lab, git and ressource\n",
    "- [x] better inclusion of R, N, ... in the kmer\n",
    "    - implemented, maybe need adjustment by value\n",
    "    - if frature of missing higher than threshold garbage\n",
    "    - if not fill missing by possible constellations\n",
    "- [x] evolution on reading frame\n",
    "    - difficult with amino conservation ORF tracker necessary\n",
    "        - e.g. BLOSUM etc.\n",
    "    - nucleotide exchange values used now, instead of amino exchange\n",
    "        - usage of Kimura's two-parameter model\n",
    "        - alpha and beta of user choice\n",
    "- [ ] stable parameters \n",
    "    - best would be algorithmic solution here\n",
    "        - number of clusters\n",
    "            - neighbors -> distance matrix -> kneedle algorithm -> epsilon\n",
    "        - sample number\n",
    "            - cluster number extraction algorithms -> sample \n",
    "    - alpha value (A -> G, C -> T)\n",
    "    - beta value (...)\n",
    "    - for more flexibility algorithmis solution was postponed to a later release\n",
    "\n",
    "- [ ] global local hybrid clustering (GLHC)\n",
    "    - idea war rejected first due to the necessary nxn space in worst case\n",
    "    - maybe precalculation reinclude into clustering in the first place useful at some point\n",
    "        - precalculation: nxn\n",
    "        - no precalculation: nxk \n",
    "        - could be usefull in the future to change to precalculation\n",
    "        - necessary for this step is the stepwise calculation of the precalc matrix\n",
    "            - d(acc1, acc2), d(acc1, acc3), d(acc1, acc4), ..., d(acc1, accn)\n",
    "            - d(acc2, ....) find a way to calculate the rest based on the first line\n",
    "    - centroids -> single linkage(centroids)\n",
    "        - difficulat to validate the quality of this method\n",
    "    - all point cluster distance (apcd) instead of centroids\n",
    "- [ ] k-mer implementation by taking only existing values into account\n",
    "    - copy and update the old code from the project\n",
    "\n",
    "## Implementation Blueprint\n",
    "\n",
    "![Class2](Clusterer.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0e43f69-8d14-4baf-bfa0-77576b87acfa",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Packages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceae35a8-25c7-4a91-ab88-3a24f33f0e7f",
   "metadata": {},
   "source": [
    "### Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b0081d0a-ccdf-4c29-aa82-654f54154c39",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import itertools as it\n",
    "from Bio import SeqIO\n",
    "from Bio.Seq import Seq\n",
    "import math\n",
    "import re\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "import multiprocessing as mp\n",
    "import umap\n",
    "import hdbscan\n",
    "import scipy.spatial.distance as ssd\n",
    "from scipy.cluster import hierarchy\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a824f9c-f26e-4894-9231-1fe16b032637",
   "metadata": {},
   "source": [
    "### Alignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "08eff79a-35e8-42a6-bee1-147a4e9e3583",
   "metadata": {},
   "outputs": [],
   "source": [
    "from io import StringIO\n",
    "from Bio import AlignIO\n",
    "from Bio.Align.Applications import MafftCommandline\n",
    "from IPython.display import display\n",
    "from Bio.Phylo.Applications import RaxmlCommandline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d490fa0-5589-4c97-b50a-234455ed43f9",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Classes and Definitions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a7c076d-0b64-4c42-8a77-569b8830b6e2",
   "metadata": {},
   "source": [
    "### Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "noticed-pitch",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Vectors(object):\n",
    "    \n",
    "    def __init__(self, k = 7, identifier = 0, split = None, quality = {'':0}, variable = 2, state = 1.0, alpha = 0.0, beta = 0.0, init = 0.0, procs = 4, preprocess = True):\n",
    "    \n",
    "        self.k = k\n",
    "        self.quality = quality\n",
    "        self.identifier = identifier\n",
    "        self.split = split\n",
    "        self.variable = variable\n",
    "        self.nucleotides = ['A', 'C', 'G', 'T']\n",
    "        self.purines = ['A', 'G']\n",
    "        self.pyrines = ['C', 'T']\n",
    "        self.exotics = ['R', 'Y', 'W', 'S', 'M', 'K', 'B', 'H', 'D', 'V', 'N']\n",
    "        #self.substit = dict.fromkeys(map(ord, self.nucleotides), None)\n",
    "        #self.exist = dict.fromkeys(map(''.join, it.product(self.nucleotides, repeat = self.k)), init)        \n",
    "        self.state = state\n",
    "        self.init = init\n",
    "        self.procs = procs\n",
    "        self.alpha = alpha\n",
    "        self.beta = beta\n",
    "        self.preprocess = preprocess\n",
    "        self.exchange = {\n",
    "            'A':['A'],\n",
    "            'C':['C'],\n",
    "            'G':['G'],\n",
    "            'T':['T'],\n",
    "            'R':['A', 'G'],\n",
    "            'Y':['C', 'T'],\n",
    "            'W':['A', 'T'],\n",
    "            'S':['C', 'G'],\n",
    "            'M':['A', 'C'],\n",
    "            'K':['G', 'T'],\n",
    "            'B':['G', 'C', 'T'],\n",
    "            'H':['A', 'C', 'T'],\n",
    "            'D':['A', 'G', 'T'],\n",
    "            'V':['A', 'C', 'G'],\n",
    "            'N':['A', 'C', 'G', 'T'],\n",
    "        } \n",
    "        self.kimura = {}\n",
    "        for nuc in self.nucleotides:\n",
    "            self.kimura[nuc] = {}\n",
    "            if self.alpha != 0.0: \n",
    "                a = self.purines if nuc in self.purines else self.pyrines\n",
    "                pos = 0 if a.index(nuc) != 0 else 1\n",
    "                self.kimura[nuc][a[pos]] = self.alpha\n",
    "            if self.beta != 0.0:\n",
    "                b = self.purines if nuc not in self.purines else self.pyrines\n",
    "                self.kimura[nuc][b[0]] = self.beta\n",
    "                self.kimura[nuc][b[1]] = self.beta\n",
    "    \n",
    "    def countRows(self, infile):\n",
    "        \n",
    "        index = []\n",
    "        record = SeqIO.index(infile, \"fasta\", key_function = lambda entry: entry.split(self.split)[self.identifier] if type(self.identifier) == int else re.search('.*' + self.identifier + '([^|]+).*', entry)[1])\n",
    "        for accession in record.keys():\n",
    "            \n",
    "            entry = record[accession]\n",
    "            header = entry.description.split(self.split)\n",
    "            sequence = str(entry.seq)\n",
    "            #missing = len(sequence.translate(self.substit))\n",
    "            #fracture = float(len(sequence)/missing) if missing else 0 \n",
    "            missing = re.findall('['+''.join(self.exotics)+']+', sequence)\n",
    "            \n",
    "            try:\n",
    "                if all([re.match(i, header[self.quality[i]], re.IGNORECASE) for i in self.quality]) == True and (0 if not missing else len(max(missing, key=len))) <= self.variable:\n",
    "                #if all([re.match(i, header[self.quality[i]], re.IGNORECASE) for i in self.quality]) == True and fracture <= 0.9:\n",
    "                    index.append(accession)\n",
    "            except:\n",
    "                pass\n",
    "        \n",
    "        return(index, record)\n",
    "    \n",
    "    def preprocessKmer(self, sequence):\n",
    "        \n",
    "        exist = []\n",
    "        for i in range(len(sequence) - self.k + 1):\n",
    "            kmer = sequence[i:i+self.k]\n",
    "            main = list(map(''.join, it.product(*[self.exchange.get(j) for j in kmer])))\n",
    "\n",
    "            for sub in main:\n",
    "                exist.append(sub)\n",
    "                #if self.kimura:\n",
    "                #    for l, nuc in enumerate(sub):\n",
    "                #        for mut in self.kimura[nuc].keys():\n",
    "                #            mutation = sub[:l] + mut + sub[l+1:]\n",
    "                            #self.exist[sub] = 0\n",
    "                #            exist.append(mutation)\n",
    "\n",
    "        return(exist)\n",
    "    \n",
    "    def calculateKmer(self, data):\n",
    "        \n",
    "        temporary, sequence = data\n",
    "        \n",
    "        for i in range(len(sequence) - self.k + 1):\n",
    "            kmer = sequence[i:i+self.k]\n",
    "            main = list(map(''.join, it.product(*[self.exchange.get(j) for j in kmer])))\n",
    "\n",
    "            for sub in main:\n",
    "                temporary[sub] += self.state/len(main)\n",
    "                if self.kimura:\n",
    "                    for l, nuc in enumerate(sub):\n",
    "                        for mut in self.kimura[nuc].keys():\n",
    "                            mutation = sub[:l] + mut + sub[l+1:]\n",
    "                            if mutation in temporary:\n",
    "                                temporary[mutation] += self.kimura[nuc][mut]\n",
    "\n",
    "        vector = np.fromiter(temporary.values(), dtype = 'float32', count = len(temporary.keys()))/sum(temporary.values())\n",
    "        temporary.clear()\n",
    "        return(vector)\n",
    "        \n",
    "    def calculateFrequence(self, infile):\n",
    "        \n",
    "        index, record = self.countRows(infile)\n",
    "        #matrix = np.empty((len(index), self.col, ),dtype = 'float32')\n",
    "        \n",
    "        if self.preprocess == True:\n",
    "            with mp.Pool(self.procs) as pool:\n",
    "                preprocessor = tqdm(pool.imap(self.preprocessKmer, map(lambda m: str(record[m].seq), index)), total = len(index), desc=\"Preprocessing\")\n",
    "                exist = dict(sorted(dict.fromkeys(it.chain.from_iterable(preprocessor), self.init).items()))\n",
    "\n",
    "        else:\n",
    "            exist = dict.fromkeys(map(''.join, it.product(self.nucleotides, repeat = self.k)), self.init)    \n",
    "                \n",
    "        shared = it.repeat(exist,len(index))\n",
    "        \n",
    "        with mp.Pool(self.procs) as pool:\n",
    "            calculator = tqdm(pool.imap(self.calculateKmer, zip(shared, map(lambda m: str(record[m].seq), index))), total = len(index), desc=\"Calculation\")\n",
    "            matrix = np.fromiter(it.chain.from_iterable(calculator), dtype = 'float32', count = len(exist.keys()) * len(index))\n",
    "            matrix.shape = len(index), len(exist.keys())\n",
    "            #for pos, vector in enumerate(calculator):\n",
    "            #    matrix[pos] = vector\n",
    "                \n",
    "        return(index, matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eb81e31-253d-41d3-aebd-8e15971c31ec",
   "metadata": {},
   "source": [
    "- execution can still be faster ca. 15-20min for segment 4 is still slow, lul now its 2 at max\n",
    "    - inclusion of mutation increased the runtime by factor 5-10, nvm multipressing easy\n",
    "    - multiprocessing difficult to implement (dicts, fast calculation of single instances high overhang)\n",
    "- all mutations and all unkown kmers (including e.g. Ns) are counted with state or respective alpha beta\n",
    "    - maybe split value by their number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6afb4be1-5c98-4a74-baf2-991f0b2e0225",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Cluster(linkage, min_clust, num_clust):\n",
    "\n",
    "    x = 0.0\n",
    "    y = 1.0\n",
    "    cluster = linkage.get_clusters(cut_distance = x, min_cluster_size = min_clust)\n",
    "    n = cluster.max().item()\n",
    "    \n",
    "    while n != num_clust:\n",
    "\n",
    "        if n < num_clust and n != -1:\n",
    "            x = x - y\n",
    "            y = y * 0.1\n",
    "\n",
    "        else:\n",
    "            x = x + y\n",
    "\n",
    "        cluster = linkage.get_clusters(cut_distance = x, min_cluster_size = min_clust)\n",
    "        n = cluster.max().item()\n",
    "        \n",
    "        if x != 0.0 and n == -1:\n",
    "            print('Error.')\n",
    "            break\n",
    "        \n",
    "    return(cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e03007cf-0d79-469f-995d-d65dee6b885a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def workerCentroid(subtuple):\n",
    "    \n",
    "    subl2, i = subtuple\n",
    "    indexdist = subl2.index.tolist()\n",
    "    calcdist = map(lambda x: ssd.cdist([x[1]], subl2, 'euclidean').mean(), subl2.iterrows())\n",
    "    framedist = pd.DataFrame(np.fromiter(calcdist, dtype = 'float32', count = len(subl2)), index = indexdist)\n",
    "    return(framedist.idxmin().item(), i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "78ad410c-a55c-492e-9bbd-36d1c8842d89",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Centroid(framecluster, framel2):\n",
    "    \n",
    "    groups = framecluster.query('cluster != -1').groupby('cluster').groups\n",
    "    \n",
    "    with mp.Pool(procs) as pool:\n",
    "        result = pool.imap(workerCentroid, map(lambda match: (framel2.loc[groups[match]], match), groups.keys()))\n",
    "        centroid = pd.DataFrame(result, columns = ['accession', 'cluster']).set_index('accession')\n",
    "        \n",
    "    return(centroid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5056fe9c-1a70-42df-a2bd-6f023476dd03",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Linkage(framecentroid, framel2, procs):\n",
    "    \n",
    "    subl2 = framel2.loc[framecentroid.index.tolist()]\n",
    "    distance = ssd.cdist(subl2, subl2, 'euclidean')\n",
    "    linkage = hierarchy.linkage(distance, method = 'single', metric = 'euclidean')\n",
    "    \n",
    "    return(linkage, distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9b25b9ef-d5b2-432c-87bc-87e1e259fb3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fillGaps(frame):\n",
    "    \n",
    "    array = frame.unique()\n",
    "    array = array[array != '']\n",
    "    if len(array) == 1:\n",
    "        frame.replace('', array[0], inplace = True)\n",
    "        frame.fillna(array[0], inplace = True)\n",
    "    else:\n",
    "        frame.replace('', 'na', inplace = True)\n",
    "        frame.fillna('na', inplace = True)\n",
    "        #changed to mixed from NA good decision?\n",
    "        \n",
    "    return(frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "576cc8c9-1607-4080-9e5e-b9970cb96129",
   "metadata": {},
   "outputs": [],
   "source": [
    "def curateFASTA(infile, split, identifier = 0, columns = {'':1}):\n",
    "    \n",
    "    meta = {ident:{} for ident in columns.keys()}\n",
    "    \n",
    "    for entry in SeqIO.parse(infile,'fasta'):\n",
    "    \n",
    "        header = entry.description.split(split)\n",
    "\n",
    "        accession = header[identifier] if type(identifier) == int else re.search('.*' + acc_ident + '([^|]+).*', entry.description)[1]\n",
    "        \n",
    "        for key in columns.keys():\n",
    "\n",
    "            position = columns[key]\n",
    "            try:\n",
    "                meta[key][accession] = header[position] if type(position) == int else '' if re.search('.*' + position + '([^|]+).*', entry.description) == None else re.search('.*' + position + '([^|]+)|.*', entry.description)[1]    \n",
    "            except:\n",
    "                meta[key][accession] = ''\n",
    "         \n",
    "    framemeta = pd.DataFrame(meta)\n",
    "    \n",
    "    return(framemeta)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52cc146b-dc7d-479b-8d50-544b809510d9",
   "metadata": {},
   "source": [
    "### Alignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0702961c-cc40-44b1-a84a-8c4cbac60908",
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_seq(accession):\n",
    "    rec = record_dict[accession]\n",
    "    #name = 'cluster_' + str(framecentroid.loc[accession].item())\n",
    "    name = accession\n",
    "    rec.id = name\n",
    "    rec.name = name\n",
    "    rec.description = name\n",
    "    return(rec)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eced3650-4720-481e-bac1-0788d897289c",
   "metadata": {},
   "source": [
    "- needs some kind of error correction e.g. when only 4 sequences 60 clusters are impossible"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "784f0866-79db-4c34-ad4f-6b0f2c927248",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Main Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92ba42cb-c330-479b-a899-905bf692ed25",
   "metadata": {},
   "source": [
    "### Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "778e7ce5-45cb-4b59-95bd-d77cf16e7238",
   "metadata": {},
   "outputs": [],
   "source": [
    "name = 'influenza_segment_7'\n",
    "k = 7\n",
    "split = '|'\n",
    "#quality = {'(?!^UNKNOWN_.*)':1}\n",
    "quality = {'pass':8, '7':2}\n",
    "identifier = 0\n",
    "variable = 0\n",
    "min_clust = 2\n",
    "sample = 1\n",
    "num_clust =  60\n",
    "n_components = 50\n",
    "procs = 10\n",
    "state = 1.0\n",
    "alpha = 0.0\n",
    "beta = 0.0\n",
    "init = 0.0\n",
    "preprocess = False\n",
    "infile = 'A.fasta'\n",
    "#infile = 'degue.fasta'\n",
    "columns = {'strain':1,'segment':2,'protein':3,'type':4,'subtype':5,'year':6,'host':7,'pass':8,'season':9,'country':10,'state':11}\n",
    "change = {'subtype':{'HA':'[H][0-9]+', 'NA':'[N][0-9]+'}}\n",
    "#feature = None#'N'\n",
    "#fill = False#True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "46096a2e-2cdf-4148-b20c-e58b5588269d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculation: 100%|██████████████████████▉| 54557/54558 [03:06<00:00, 292.21it/s]\n"
     ]
    }
   ],
   "source": [
    "vectors = Vectors(k = k, identifier = identifier, split = split, quality = quality, variable = variable, state = state, alpha = alpha, beta = beta, init = init, procs = procs, preprocess = preprocess)\n",
    "index, matrixl1 = vectors.calculateFrequence(infile = infile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6f6b91d2-c062-4252-bada-88905a98f14b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components = n_components)\n",
    "matrixpca = pca.fit_transform(matrixl1)\n",
    "variance = pca.explained_variance_ratio_.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d64e8455-773b-442c-ade0-e60a1a2b093a",
   "metadata": {},
   "outputs": [],
   "source": [
    "matrixl2 = normalize(matrixpca, norm='l2')\n",
    "#precomputed = ssd.cdist(matrixl2, matrixl2, 'euclidean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c6dc9880-ec6c-4b7e-94ee-efb07a37f39f",
   "metadata": {},
   "outputs": [],
   "source": [
    "hdbinit = hdbscan.HDBSCAN(min_samples = sample, min_cluster_size = min_clust, gen_min_span_tree = False, metric = 'euclidean', core_dist_n_jobs = -1).fit(matrixl2)\n",
    "#hdbinit = hdbscan.HDBSCAN(min_samples = sample, min_cluster_size = min_clust, gen_min_span_tree = True, metric = 'precomputed').fit(precomputed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b6fe1c1a-ba5f-4249-be53-c48c4ed8c0e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "linklocal = hdbinit.single_linkage_tree_\n",
    "framelocal = linklocal.to_pandas().drop(['parent'], axis=1)#.set_index('parent', inplace = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7f64d4be-e194-43a8-a6d1-1822de17d252",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster = Cluster(linklocal, min_clust, num_clust) \n",
    "framecluster = pd.DataFrame(cluster, columns = ['cluster'], index = index)\n",
    "framecluster.index.rename('accession', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a3ffba6-8814-4ed2-a4b2-b8d008a22e99",
   "metadata": {},
   "outputs": [],
   "source": [
    "framel2 = pd.DataFrame(matrixl2, index = index)\n",
    "framecentroid = Centroid(framecluster, framel2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d3db667-ff37-4e59-9b8c-218e45269185",
   "metadata": {},
   "outputs": [],
   "source": [
    "unclustered = len(framecluster.query('cluster == -1'))\n",
    "clustered = len(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bceb9676-475c-4477-b639-c3e53b1ffa0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(f'Vector Dimensionality:\\t{matrixl1.shape[1]}\\nUnclustered Fracture:\\t{unclustered/clustered*100:.4f}%\\nExplained Variance:\\t{variance*100:.4f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "370e9d9e-d1da-43a6-a217-659fd42a02a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "framemeta = curateFASTA(infile = infile, split = split, identifier = identifier, columns = columns)\n",
    "#treequery = framecluster.join(framemeta)\n",
    "framemeta.index.rename('accession', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12a73d68-c8e7-474c-837e-24512501fc62",
   "metadata": {},
   "outputs": [],
   "source": [
    "if change:\n",
    "    for key in change.keys():\n",
    "        for col in change[key].keys():\n",
    "            framemeta[col] = framemeta[key].apply(lambda x: re.search(change[key][col], x).group(0) if re.search(change[key][col], x) else 'mixed').tolist()\n",
    "#if fill == True:\n",
    "#    treequery[feature] = treequery.groupby(by = ['cluster'])[feature].apply(lambda x : fillGaps(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da55e1ea-fc9e-4f9e-bcce-6d6e18c74cb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "framemeta.to_csv('meta_' + name + '.csv', index=True, header=True, sep=',', mode='w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ef9932d-34be-4843-821f-2acd77526fc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "framecluster.to_csv('cluster_' + name + '.csv', index=True, header=True, sep=',', mode='w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc16fd7b-b62f-4408-815e-72155a995b72",
   "metadata": {},
   "outputs": [],
   "source": [
    "#treequery.replace('', 'na', inplace = True)\n",
    "#treequery.replace(np.nan, 'na', inplace = True)\n",
    "#treequery.to_csv('cluster_' + name + '.csv', index=True, header=True, sep=',', mode='w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f059a583-5d06-41cc-92cb-b111280608b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "count = framecluster.query('cluster != -1')['cluster'].value_counts().rename('size')\n",
    "treecentroid = framecentroid.reset_index().set_index('cluster').join(count).reset_index().set_index('accession')#.join(treequery.drop('cluster', axis=1))\n",
    "treecentroid.to_csv('centroids_' + name + '.csv', index=True, header=True, sep=',', mode='w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8067bb01-8d1e-41aa-bafc-9f15835ef32b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pcashow = PCA(n_components = 200)\n",
    "pcashow.fit_transform(matrixl1)\n",
    "exp_var_cumul = np.cumsum(pcashow.explained_variance_ratio_)\n",
    "x = range(1, exp_var_cumul.shape[0] + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43bbbf92-15b3-429d-8eb9-9c896282a225",
   "metadata": {},
   "outputs": [],
   "source": [
    "framepca = pd.DataFrame({'components':x, 'variance':exp_var_cumul})\n",
    "framepca.set_index('components', inplace = True)\n",
    "framepca.to_csv('pca_' + name + '.csv', index=True, header=True, sep=',', mode='w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0315d821-f2c4-481f-94c3-851d0fcfe714",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca3d = PCA(n_components = 3)\n",
    "matrixpca3d = pca3d.fit_transform(matrixl1)\n",
    "matrix3d = normalize(matrixpca3d, norm='l2')\n",
    "frame3d = pd.DataFrame(matrix3d, columns = ['x', 'y', 'z'], index = index)\n",
    "frame3d.index.rename('accession', inplace=True)\n",
    "frame3d.to_csv('vectors_' + name + '.csv', index=True, header=True, sep=',', mode='w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "683d96a7-4879-479f-8bfc-e8d3d29cf63e",
   "metadata": {},
   "outputs": [],
   "source": [
    "frameinfo = pd.DataFrame({'name': name, 'sequences': len(index), 'cluster': num_clust, 'unclustered': unclustered, 'components': n_components, 'variance': variance}, index=[0])\n",
    "frameinfo.to_csv('info_' + name + '.csv', index=False, header=True, sep=',', mode='w')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15a080fa-a0cd-4869-8857-e43565679bc9",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Alignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adf2d372-f2ee-47b2-99a8-d6adc436fa8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "record_dict = SeqIO.index(infile, \"fasta\", key_function = lambda entry: entry.split('|')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "520835a2-5874-4f9a-afa0-4853fca7ef70",
   "metadata": {},
   "outputs": [],
   "source": [
    "#_ = SeqIO.write(map(lambda x: record_dict[x], centr), \"temp.fasta\", \"fasta\")\n",
    "_ = SeqIO.write(map(change_seq, treecentroid.index.tolist()), 'centroids_' + name + '.fasta', 'fasta')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d154e481-f1f3-4e3e-92aa-b14772a48fda",
   "metadata": {},
   "outputs": [],
   "source": [
    "in_file = 'centroids_' + name + '.fasta'\n",
    "mafft_cline = MafftCommandline(input = in_file, thread = 16, treeout = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "056ed529-03dd-415e-bbb4-83c8905db5e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "stdout, stderr = mafft_cline()\n",
    "align = AlignIO.read(StringIO(stdout), \"fasta\")\n",
    "_ = AlignIO.write(align, 'centroids_' + name + '.msa', 'fasta')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e47b868-6dd2-4fb5-a90c-82c1d5d3183a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('centroids_' + name + '.fasta.tree', 'r') as read:\n",
    "    #update = re.sub('\\d+_(.*?)_.*?([:|\\n])', r'\\1\\2', read.read())\n",
    "    update = re.sub('\\d+_(.*?)([:|\\n])', r'\\1\\2', read.read())\n",
    "with open('centroids_' + name + '.fasta.tree', 'w') as write:\n",
    "    write.write(update)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1afea0f8-729c-412c-954d-e80288069d3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "raxml_cline = RaxmlCommandline(\n",
    "    sequences = 'centroids_' + name + '.msa', \n",
    "    model = 'GTRGAMMA', \n",
    "    name = name + '.tree', \n",
    "    rapid_bootstrap_seed = 1234, \n",
    "    threads = procs, \n",
    "    num_replicates = 100, \n",
    "    algorithm = 'a', \n",
    "    parsimony_seed = 1234\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be9f2cc5-0421-4275-ac24-9d0d44b1adc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "stdout, stderr = raxml_cline()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "625db32a-1deb-4ed2-a5f8-0f1bfdcfef57",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Garbage Place"
   ]
  },
  {
   "cell_type": "raw",
   "id": "9793afd8-7277-457b-8913-b744b4ca6e3b",
   "metadata": {},
   "source": [
    "columns = {'name':1,'segment':2,'protein':3,'type':4,'subtype':5,'year':6,'host':7,'pass':8,'season':9,'country':10,'state':11}\n",
    "#columns = {'name':1,'segment':2,'year':3,'host':4,'country':5,'subtype':6,'type':7,}\n",
    "change = {'subtype':{'H':'[H][0-9]+', 'N':'[N][0-9]+'}}\n",
    "#change = {}\n",
    "feature = 'H'\n",
    "#feature = 'type'\n",
    "#rownumber = 2\n",
    "#prune = True\n",
    "fill = True\n",
    "#treshold = 1.0\n",
    "#listcolor = ['#FF0029','#377EB8','#66A61E','#984EA3','#00D2D5','#FF7F00','#AF8D00','#7F80CD','#B3E900','#C42E60','#A65628',\n",
    "#             '#F781BF','#8DD3C7','#BEBADA','#FB8072','#80B1D3','#FDB462','#FCCDE5','#99A893','#EED5D2','#3F00FF','#DABF86']"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c27af6cb-f839-49f0-815c-29a95a75d448",
   "metadata": {},
   "source": [
    "#fig = px.area(x=range(1, exp_var_cumul.shape[0] + 1), y=exp_var_cumul, labels={\"x\": \"# Components\", \"y\": \"Explained Variance\"})\n",
    "#fig.update_layout(autosize = True, width = 1000, height = 500, \n",
    "#                  margin = dict(l=0, r=0, b=0, t=0),\n",
    "#                 )\n",
    "\n",
    "#fig.write_html('pca_components.html', auto_open=False)\n",
    "#fig_widget = go.FigureWidget(fig)\n",
    "#fig_widget"
   ]
  },
  {
   "cell_type": "raw",
   "id": "7061f864-76cc-4f15-b1ac-ae1ac27308e4",
   "metadata": {},
   "source": [
    "#linkglobal, distance = Linkage(framecentroid, framel2, procs)\n",
    "#frameglobal = pd.DataFrame(linkglobal, columns = ['left_child', 'right_child', 'distance', 'size'])"
   ]
  },
  {
   "cell_type": "raw",
   "id": "17ebb481-4ff0-4202-844c-02f6502fc8f3",
   "metadata": {},
   "source": [
    "#framecluster.to_csv('cluster.csv', index=True, header=True, sep=',', mode='w')\n",
    "#framelocal.to_csv('vectors.csv', index=False, header=True, sep=',', mode='w')\n",
    "#frameglobal.to_csv('global.csv', index=False, header=True, sep=',', mode='w')\n",
    "#framecentroid.to_csv('centroid.csv', index=True, header=True, sep=',', mode='w')"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e2f49bf2-2f5f-496a-9032-b7f1f0eb789b",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Tree"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f93bbbdf-1093-4cbc-b205-e05480a365c6",
   "metadata": {},
   "source": [
    "import collections as co\n",
    "import seaborn as sns\n",
    "from ete3 import PhyloTree, Tree, faces, AttrFace, CircleFace, TreeStyle, NodeStyle, TextFace, RectFace, SequenceFace\n",
    "from matplotlib import colors\n",
    "from natsort import natsorted\n",
    "import random\n",
    "import os\n",
    "os.environ['QT_QPA_PLATFORM'] = 'offscreen'"
   ]
  },
  {
   "cell_type": "raw",
   "id": "0360bdba-a670-4b97-8a11-3234a606c40c",
   "metadata": {},
   "source": [
    "### 3D Plot"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ec872967-cb23-4662-ba13-bafc3608223d",
   "metadata": {},
   "source": [
    "import matplotlib.pyplot as plt\n",
    "#import seaborn as sns\n",
    "#from mpl_toolkits.mplot3d import Axes3D\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f1cfc982-9122-46f1-8220-d027dfeb6bb3",
   "metadata": {},
   "source": [
    "### Tree"
   ]
  },
  {
   "cell_type": "raw",
   "id": "267fe908-4110-426b-88ef-2295b2b460d7",
   "metadata": {},
   "source": [
    "def getNewick(node, newick, parentdist, leaf_names):\n",
    "    \n",
    "    if node.is_leaf():\n",
    "        return(leaf_names[node.id] + \":\" + np.format_float_positional(parentdist - node.dist) + newick)\n",
    "        #return \"%s:%.5f%s\" % (leaf_names[node.id], parentdist - node.dist, newick)\n",
    "    \n",
    "    else:\n",
    "        if len(newick) > 0:\n",
    "            newick = \"):\" + np.format_float_positional(parentdist - node.dist) + newick\n",
    "            #newick = \"):%.5f%s\" % (parentdist - node.dist, newick)\n",
    "        else:\n",
    "            newick = \");\"\n",
    "        newick = getNewick(node.get_left(), newick, node.dist, leaf_names)\n",
    "        newick = getNewick(node.get_right(), \",\" + newick, node.dist, leaf_names)\n",
    "        #newick = getNewick(node.get_right(), \",%s\" % (newick), node.dist, leaf_names)\n",
    "        \n",
    "        newick = \"(\" + newick\n",
    "        #newick = \"(%s\" % (newick)\n",
    "        return(newick)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ec1f4948-e2d2-4d70-8688-2cd3423e3ff6",
   "metadata": {},
   "source": [
    "def getVector(frame, components, col):\n",
    "\n",
    "    duplicate = components.copy()\n",
    "    duplicate.update(frame[col].value_counts().to_dict())\n",
    "    \n",
    "    vector = pd.DataFrame([duplicate.values()])\n",
    "    duplicate.clear()\n",
    "    \n",
    "    return(vector)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b9ef7e0e-ebee-4541-8df9-59e1d869f583",
   "metadata": {},
   "source": [
    "def getlocalTree(framelink, treequery, feature = 'hostsel', rownumber = 2, prune = True, treshold = 0.5, listcolor = []):\n",
    "    \n",
    "    treelabel = treequery.index.values\n",
    "    treestyle = TreeStyle()\n",
    "    \n",
    "    treelink = framelink.to_numpy()\n",
    "    treehierarchy = hierarchy.to_tree(treelink, False)\n",
    "    treenewick = getNewick(treehierarchy, \"\", treehierarchy.dist, treelabel)\n",
    "    tree = Tree(treenewick)\n",
    "        \n",
    "    treedict = treequery[['cluster', feature]].to_dict()\n",
    "    listfeature = natsorted(list(set(treedict[feature].values())))\n",
    "\n",
    "    treecomponents = dict.fromkeys(listfeature, 0)\n",
    "    featurevectors = treequery[['cluster', feature]].groupby(by=['cluster']).apply(lambda x: getVector(x, treecomponents, feature))\n",
    "    featurevectors.reset_index(level = 1, drop = True, inplace=True)\n",
    "\n",
    "    listcluster = featurevectors.index.tolist()\n",
    "    featurel1vectors = normalize(featurevectors.to_numpy(), norm='l1')\n",
    "    framefeature = pd.DataFrame(featurel1vectors, index = listcluster, columns = listfeature)\n",
    "    \n",
    "    if treshold != 0.0:\n",
    "        listfeature.append('mixed')\n",
    "    \n",
    "    if not listcolor or len(listfeature) > len(listcolor):\n",
    "        listcolor = [\"#%06X\" % random.randint(0, 0xFFFFFF) for f in listfeature]\n",
    "    \n",
    "    dictcolor = dict(zip(listfeature, listcolor[0:len(listfeature)]))\n",
    "    prunecluster = []\n",
    "    usedfeature = []\n",
    "    \n",
    "    for node in tree.traverse():\n",
    "        node.img_style[\"vt_line_width\"] = 0.5\n",
    "        node.img_style[\"hz_line_width\"] = 0.5\n",
    "        node.img_style[\"vt_line_type\"] = 0\n",
    "        node.img_style[\"hz_line_type\"] = 0\n",
    "        node.img_style[\"fgcolor\"] = \"#000000\"\n",
    "        node.img_style[\"shape\"] = \"circle\"\n",
    "        node.img_style[\"size\"] = 1\n",
    "        node.img_style[\"vt_line_color\"] = \"#000000\"\n",
    "        node.img_style[\"hz_line_color\"] = \"#000000\"\n",
    "        node.img_style['bgcolor'] = 'lightgrey'\n",
    "    \n",
    "    for leaf in tree.iter_leaves():\n",
    "        leaf.feature = treedict[feature].get(leaf.name, \"none\")\n",
    "        leaf.cluster = treedict['cluster'].get(leaf.name, \"none\")\n",
    "        leaf.img_style['bgcolor'] = dictcolor[leaf.feature]\n",
    "        \n",
    "    if -1 in listcluster:\n",
    "        listcluster.remove(-1)\n",
    "    \n",
    "    for cluster in listcluster:\n",
    "        listmember = tree.search_nodes(cluster=cluster)\n",
    "        nodecluster = tree.get_common_ancestor(listmember)\n",
    "        nodecluster.name = f'cluster {cluster}'\n",
    "        nodecluster.size = len(listmember)\n",
    "\n",
    "        frame = framefeature.loc[cluster].sort_values(axis=0, ascending=False)\n",
    "\n",
    "        if treshold != 0.0:\n",
    "            nodecluster.feature = (frame.idxmax() if frame.max() >= treshold else 'mixed')\n",
    "        else:\n",
    "            nodecluster.feature = frame.idxmax()\n",
    "        \n",
    "        if nodecluster.feature not in usedfeature:\n",
    "            usedfeature.append(nodecluster.feature)\n",
    "            \n",
    "        nodecluster.add_face(AttrFace(\"name\", fsize = 6, ftype = 'Arial'), 0, position=\"aligned\")\n",
    "        nodecluster.add_face(AttrFace(\"size\", fsize = 6, ftype = 'Arial', text_prefix='|', text_suffix='|'), 1, position=\"aligned\") \n",
    "        nodecluster.img_style['bgcolor'] = dictcolor[nodecluster.feature]\n",
    "\n",
    "        prunecluster.append(nodecluster.name)    \n",
    "\n",
    "    if prune == True:\n",
    "        tree.prune(prunecluster)\n",
    "       \n",
    "    treestyle =  TreeStyle()\n",
    "    treestyle.show_leaf_name = False\n",
    "    treestyle.draw_guiding_lines = True\n",
    "    treestyle.guiding_lines_color = 'black'\n",
    "    treestyle.mode = \"c\"\n",
    "    treestyle.allow_face_overlap = False\n",
    "\n",
    "    column = 0\n",
    "    \n",
    "    for i, feature in enumerate(natsorted(usedfeature), 1): \n",
    "        #legendcolor = RectFace(width = 20, height = 20, fgcolor = \"#000000\", bgcolor = dictcolor[feature], label = None)\n",
    "        legendcolor = CircleFace(radius = 2.5, color = dictcolor[feature], label = None)\n",
    "        treestyle.legend.add_face(legendcolor, column = column)\n",
    "        legendtext = TextFace(feature, ftype = 'Arial', fsize = 6)\n",
    "        legendtext.margin_right = 10\n",
    "        legendtext.margin_left = 5\n",
    "        treestyle.legend.add_face(legendtext, column = column + 1)\n",
    "\n",
    "        if i%rownumber == 0:\n",
    "            column = column + 2\n",
    "\n",
    "    treestyle.legend_position = 1\n",
    "        \n",
    "    return(tree, treestyle, dictcolor)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e388e721-739b-40b1-a377-3c38ea9aa8aa",
   "metadata": {},
   "source": [
    "with open(\"output.newick\", \"w\") as f:\n",
    "    treelabel = framecluster.index.values\n",
    "    treelink = framelocal.to_numpy()\n",
    "    treehierarchy = hierarchy.to_tree(treelink, False)\n",
    "    treenewick = getNewick(treehierarchy, \"\", treehierarchy.dist, treelabel)\n",
    "    f.write(treenewick)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "1768d48c-f51b-4047-b8f0-97f40302c141",
   "metadata": {},
   "source": [
    "### Tree"
   ]
  },
  {
   "cell_type": "raw",
   "id": "16f3d503-f314-4cd0-8202-9aa8b53556e9",
   "metadata": {},
   "source": [
    "tree, ts, dictcolor = getlocalTree(framelocal, treequery, feature = feature, rownumber = rownumber, prune = prune, treshold = treshold, listcolor = listcolor)\n",
    "#_ = tree.render(file_name = 'clustertree_degue_220106.pdf', tree_style = ts, w = 500)\n",
    "_ = tree.render(file_name = 'clustertree_influenza_segment_4_220107.pdf', tree_style = ts, w = 500)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "5f2c4780-f526-4264-8b9f-670d4e5b9c4d",
   "metadata": {},
   "source": [
    "ts.scale_length = 0.25\n",
    "ts.show_scale = False"
   ]
  },
  {
   "cell_type": "raw",
   "id": "873931b8-9597-4fff-8605-8def359e74b9",
   "metadata": {},
   "source": [
    "tree.render(file_name = '%%inline', tree_style = ts, w = 600)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "9e769c42-7cb7-43bf-9cad-14345cda1e1a",
   "metadata": {},
   "source": [
    "pca3d = PCA(n_components = 3)\n",
    "matrixpca3d = pca3d.fit_transform(matrixl1)\n",
    "matrix3d = normalize(matrixpca3d, norm='l2')\n",
    "frame3d = pd.DataFrame(matrix3d, columns = ['x', 'y', 'z'], index = index)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ae22c1aa-ed93-4529-aebf-0bd4b05b54af",
   "metadata": {},
   "source": [
    "clust3d = treequery.join(frame3d)\n",
    "centr = framecentroid.index.tolist()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "440013c5-4632-45cb-b4bd-7d7d97a5a6a8",
   "metadata": {},
   "source": [
    "clust3d.loc[centr, 'centroid'] = True\n",
    "clust3d['centroid'].replace(np.nan, False, inplace = True)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c324ffa1-26c4-4426-873e-a52a51daf435",
   "metadata": {},
   "source": [
    "clust3d[feature] = clust3d[feature].astype('category')\n",
    "clust3d[feature].cat.reorder_categories(natsorted(set(clust3d[feature])), inplace=True, ordered=True)\n",
    "clust3d.sort_values(feature, inplace = True)\n",
    "\n",
    "clust3d.reset_index(inplace = True)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "079182ff-3a56-4b7c-888d-a27018911e24",
   "metadata": {},
   "source": [
    "fig = px.scatter_3d(clust3d.query('cluster != -1 & centroid != True'), x = 'x', y = 'y', z = 'z', color = feature, hover_data=['index', 'cluster', 'name', 'year', 'host'], color_discrete_sequence = listcolor, labels={\"x\": \"PC1\", \"y\": \"PC2\", \"z\": \"PC3\"})\n",
    "fig.update_traces(marker_size = 1)\n",
    "fig.update_layout(autosize = True, width = 500, height = 500, \n",
    "                  margin = dict(l=0, r=0, b=0, t=0), \n",
    "                  scene = dict(xaxis = dict(nticks=20, range=[-1,1],), \n",
    "                               yaxis = dict(nticks=20, range=[-1,1],), \n",
    "                               zaxis = dict(nticks=20, range=[-1,1],),\n",
    "                               aspectmode = 'cube',\n",
    "                              ),\n",
    "                  legend=dict(orientation = 'v',\n",
    "                              yanchor=\"middle\",\n",
    "                              y=0.5,\n",
    "                              #xanchor=\"right\",\n",
    "                              #x=1,\n",
    "                              itemsizing='constant',\n",
    "                              #itemwidth = 30,\n",
    "                             ),\n",
    "                 )           \n",
    "\n",
    "#fig = go.Figure(data=[go.Scatter3d(x=clust3d.x, y=clust3d.y, z=clust3d.z, mode='markers', marker=dict(size=1, color = clust3d.H, opacity=0.8))])\n",
    "    \n",
    "fig.write_html('sphere_influenza_segment_4.html', auto_open=False)\n",
    "fig_widget = go.FigureWidget(fig)\n",
    "fig_widget"
   ]
  },
  {
   "cell_type": "raw",
   "id": "31905b32-59ea-41e3-9839-2a4f0264ad30",
   "metadata": {},
   "source": [
    "# Set up 100 points. First, do angles\n",
    "theta = np.linspace(0,2*np.pi,100)\n",
    "phi = np.linspace(0,np.pi,100)\n",
    "\n",
    "# Set up coordinates for points on the sphere\n",
    "x0 = 1 * np.outer(np.cos(theta),np.sin(phi))\n",
    "y0 = 1 * np.outer(np.sin(theta),np.sin(phi))\n",
    "z0 = 1 * np.outer(np.ones(100),np.cos(phi))\n",
    "\n",
    "# Set up trace\n",
    "trace = go.Surface(x=x0, y=y0, z=z0, colorscale=[[0,'lightgray'], [1,'lightgray']], opacity=0.9, name = 'Unit Sphere')\n",
    "trace.update(showscale=False)\n",
    "\n",
    "#surface = go.Scatter3d(x=clust3d.x, y=clust3d.y, z=clust3d.z, mode='markers', marker=dict(size=1, opacity=1, color = clust3d.color), name = 'Influenza A Virus')\n",
    "surface = px.scatter_3d(clust3d, x = 'x', y = 'y', z = 'z', color = feature, hover_data=['index', 'cluster', 'name', 'year', 'host'], color_discrete_sequence = listcolor, labels={\"x\": \"PC1\", \"y\": \"PC2\", \"z\": \"PC3\"})\n",
    "#print(surface['data'])\n",
    "\n",
    "fig = go.Figure(data = [trace, surface[0]])\n",
    "\n",
    "fig.update_layout(autosize = True, width = 800, height = 800, \n",
    "                  margin = dict(l=0, r=0, b=0, t=0), \n",
    "                  scene = dict(xaxis = dict(nticks=20, range=[-1,1],), \n",
    "                               yaxis = dict(nticks=20, range=[-1,1],), \n",
    "                               zaxis = dict(nticks=20, range=[-1,1],),\n",
    "                               aspectmode = 'cube',\n",
    "                              ),\n",
    "                  legend=dict(orientation = 'v',\n",
    "                              yanchor=\"middle\",\n",
    "                              y=0.5,\n",
    "                              #xanchor=\"right\",\n",
    "                              #x=1,\n",
    "                              itemsizing='constant',\n",
    "                              #itemwidth = 30,\n",
    "                             ),\n",
    "                 )           \n",
    "\n",
    "fig.write_html('pca_components.html', auto_open=False)\n",
    "fig_widget = go.FigureWidget(fig)\n",
    "fig_widget"
   ]
  },
  {
   "cell_type": "raw",
   "id": "9b6a36c7-9676-413d-9a43-6fc642bfc274",
   "metadata": {},
   "source": [
    "%matplotlib widget\n",
    "\n",
    "fig = plt.figure(figsize=(12,12))\n",
    "ax = fig.add_subplot(111, projection = '3d')\n",
    "\n",
    "ax.set_title(\"Unitsphere Vector Representation\")\n",
    "ax.set_xlabel('x-axis')\n",
    "ax.set_ylabel('y-axis')\n",
    "ax.set_zlabel('z-axis')\n",
    "ax.set(xlim=(-1, 1), ylim=(-1, 1), zlim=(-1,1))\n",
    "\n",
    "#u = np.linspace(0, 2 * np.pi, 100)\n",
    "#v = np.linspace(0, np.pi, 100)\n",
    "#x = 1 * np.outer(np.cos(u), np.sin(v))\n",
    "#y = 1 * np.outer(np.sin(u), np.sin(v))\n",
    "#z = 1 * np.outer(np.ones(np.size(u)), np.cos(v))\n",
    "\n",
    "# Plot the surface\n",
    "#ax.plot_surface(x, y, z, color='lightgray', alpha = 1, zorder=10)\n",
    "\n",
    "groups = clust3d.groupby(feature)\n",
    "\n",
    "for name, group in groups:\n",
    "    ax.scatter(xs = group.x, ys = group.y, zs = group.z, c = dictcolor[name], marker='o', s = 2, alpha = 1, label = name, zorder=0)#, depthshade = 1)\n",
    "    \n",
    "legend = ax.legend(ncol = 3, markerscale = 5, frameon=False)\n",
    "handles = legend.legendHandles\n",
    "\n",
    "for i, handle in enumerate(handles):\n",
    "    handle.set_alpha(1.0)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a021240e-7b7c-4c05-87fa-07da516e7f3a",
   "metadata": {},
   "source": [
    "## Results\n",
    "\n",
    "![Result](Result.svg)\n",
    "\n",
    "- NO CHANGE of H7 and H15 and H4 and H14!\n",
    "    - mixing of subtypes correct?"
   ]
  },
  {
   "cell_type": "raw",
   "id": "6a64ea3c-973b-4dd9-8393-d08c3d5b674d",
   "metadata": {},
   "source": [
    "def workerMatrix(vectors):\n",
    "    \n",
    "    x,y,i,j = vectors\n",
    "    dist = np.sqrt(np.sum((x - y) ** 2))\n",
    "    return((i,j),dist)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "302eb144-7dd7-4449-983c-a27ffbcb4031",
   "metadata": {},
   "source": [
    "def Matrix(index, matrixl1):\n",
    "\n",
    "    widgets = [' [', progressbar.Timer(format = 'elapsed time: %(elapsed)s'), '] ', progressbar.Bar('#'),' (', progressbar.ETA(), ') ', ]\n",
    "    bar = progressbar.ProgressBar(max_value = len(index)**2, widgets = widgets).start()\n",
    "\n",
    "    matrixcos = np.empty((len(index), len(index), ),dtype = 'float32')\n",
    "\n",
    "    with mp.Pool(procs) as pool:\n",
    "        result = pool.imap(workerMatrix, map(lambda pos: (matrixl1[pos[0]], matrixl1[pos[1]], pos[0], pos[1]), it.product(range(0,len(index)-1), repeat = 2)))\n",
    "        for (i,j),dist in result:\n",
    "            matrixcos[i][j] = dist\n",
    "\n",
    "            bar.update(i*len(index)+j)\n",
    "\n",
    "    bar.finish()\n",
    "    \n",
    "    return(matrixcos)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "9e356418-7269-4b1c-979e-9d5bfb78e34d",
   "metadata": {},
   "source": [
    "Matrix(index[0:1000], matrixl1)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "7262ba44-bc72-42f6-a614-d468880066e4",
   "metadata": {},
   "source": [
    "def workerLinkage(subtuple):\n",
    "    \n",
    "    subxl2, subyl2, i, j = subtuple\n",
    "    indexdist = subxl2.index.tolist()\n",
    "    calcdist = map(lambda x: ssd.cdist([x[1]], subyl2, 'euclidean').mean(), subxl2.iterrows())\n",
    "    meandist = np.fromiter(calcdist, dtype = 'float32', count = len(subxl2)).mean()\n",
    "    return(meandist,i,j)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c894a861-9a28-4373-b5b9-ed4877700d52",
   "metadata": {
    "tags": []
   },
   "source": [
    "def Centroid(framecluster, framel2):\n",
    "    \n",
    "    num = framecluster['cluster'].max()+1\n",
    "    accessions = []\n",
    "\n",
    "    for i in range(num):\n",
    "\n",
    "        query = framecluster.query('cluster == @i')\n",
    "        match = query.index.values.tolist()\n",
    "        sub = framel2.loc[match]\n",
    "\n",
    "        if not sub.empty:\n",
    "\n",
    "            tuple_min = (0, '')\n",
    "            for name, row in sub.iterrows():\n",
    "\n",
    "                if not tuple_min[1]:\n",
    "                    dist_min = ssd.cdist([row], sub, 'euclidean').mean()\n",
    "                    tuple_min = (dist_min, name)\n",
    "                else:\n",
    "                    dist_min = ssd.cdist([row], sub, 'euclidean').mean()\n",
    "                    if dist_min < tuple_min[0]:\n",
    "                        tuple_min = (dist_min, name)\n",
    "\n",
    "            accessions.append((tuple_min[1], i))\n",
    "            \n",
    "    centroid = pd.DataFrame(accessions, columns = ['accession', 'cluster']).set_index('accession')\n",
    "        \n",
    "    return(centroid)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "6d4dd199-0f38-4805-b612-968766df1f91",
   "metadata": {},
   "source": [
    "cl = framecluster.groupby('cluster', as_index=True).agg(n_matches=('cluster', 'count')).sort_values('n_matches', ascending=False).idxmax().item()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "8b80c41b-c867-4753-883a-4d8ff1f2c0c1",
   "metadata": {},
   "source": [
    "sub = framel2.loc[framecluster.query('cluster == @cl').index.tolist()]"
   ]
  },
  {
   "cell_type": "raw",
   "id": "23e4f435-fb38-4860-b3cf-5c3e5a07e827",
   "metadata": {},
   "source": [
    "test = ssd.cdist(sub, sub, 'euclidean')"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a8dac7ac-f21c-49c1-90c7-abd4e0ba0136",
   "metadata": {},
   "source": [
    "cluster.insert(2, 'centroid', False)\n",
    "\n",
    "num = cluster['cluster'].max()+1\n",
    "values = [True]*num\n",
    "accessions = []\n",
    "\n",
    "for i in range(num):\n",
    "\n",
    "    query = cluster.query('cluster == @i')\n",
    "    match = query.index.values.tolist()\n",
    "    sub = dataframe.loc[match]\n",
    "\n",
    "    if not sub.empty:\n",
    "\n",
    "        tuple_min = (0, '')\n",
    "        for name, row in sub.iterrows():\n",
    "\n",
    "            if not tuple_min[1]:\n",
    "                dist_min = ssd.cdist([row], sub, metric).mean()\n",
    "                tuple_min = (dist_min, name)\n",
    "            else:\n",
    "                dist_min = ssd.cdist([row], sub, metric).mean()\n",
    "                if dist_min < tuple_min[0]:\n",
    "                    tuple_min = (dist_min, name)\n",
    "\n",
    "        accessions.append(tuple_min[1])"
   ]
  },
  {
   "cell_type": "raw",
   "id": "5697df5a-f35c-43de-8ddc-9a73fca5c02a",
   "metadata": {
    "tags": []
   },
   "source": [
    "from itertools import repeat\n",
    "import multiprocessing as mp\n",
    "import os\n",
    "import pprint\n",
    "\n",
    "def f(d: dict) -> None:\n",
    "    pid = os.getpid()\n",
    "    d[pid] = \"Hi, I was written by process %d\" % pid\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    with mp.Manager() as manager:\n",
    "        d = manager.dict()\n",
    "        with manager.Pool() as pool:\n",
    "            pool.map(f, repeat(d, 10))\n",
    "        # `d` is a DictProxy object that can be converted to dict\n",
    "        pprint.pprint(dict(d))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "82913ae1-85fa-4ac1-bd51-6bd30973bd94",
   "metadata": {
    "tags": []
   },
   "source": [
    "def calculateFragment(self, accession):\n",
    "        \n",
    "        sequence = self.sequences[accession]\n",
    "        for i in range(len(sequence) - self.k + 1):\n",
    "\n",
    "            kmer = sequence[i:i+self.k]\n",
    "            main = map(''.join, it.product(*[self.nucex.get(j) for j in kmer]))\n",
    "\n",
    "            for sub in main:\n",
    "                self.exist[sub] += self.state\n",
    "                for l, nuc in enumerate(sub):\n",
    "                    for mut in self.nucmut[nuc]:\n",
    "                        mutation = sub[:l] + mut + sub[l+1:]\n",
    "                        self.exist[mutation] += self.nucval[(nuc,mut)]\n",
    "\n",
    "        vector = np.fromiter(self.exist.values(), dtype = 'float32', count = self.col)/sum(self.exist.values())\n",
    "        return(vector)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d1bf4682-7af0-4250-84e3-ca9f6382b26e",
   "metadata": {
    "tags": []
   },
   "source": [
    "#from kneed import DataGenerator, KneeLocator\n",
    "#import matplotlib.pyplot as plt\n",
    "\n",
    "#from scipy.signal import savgol_filter\n",
    "#from sklearn.neighbors import NearestNeighbors\n",
    "#import networkx as nx"
   ]
  },
  {
   "cell_type": "raw",
   "id": "0a0cbb5c-2265-4d07-9b8d-b59486d7c4b9",
   "metadata": {
    "tags": []
   },
   "source": [
    "                #    size = np.prod([len(self.nucex.get(k)) for k in kmer])\n",
    "                # for sub in main:\n",
    "                #    self.exist[sub] += float(1/size)\n",
    "                #    self.exist[sub] += float((1-self.mutfac)/size)     \n",
    "                #    for l, nuc in enumerate(sub):\n",
    "                #        for mutation in map(''.join, it.product(*[[sub[:l]], self.nucmut.get(nuc), [sub[l+1:]]])):\n",
    "                #            self.exist[mutation] += float(self.mutfac/(size*12))\n",
    "                #        for mutation in map(''.join, it.product(*[[sub[:l]], self.nucmut.get(nuc), [sub[l+1:]]])):\n",
    "                #            self.exist[mutation] += self.nucval[(nuc,mutation[l])]"
   ]
  },
  {
   "cell_type": "raw",
   "id": "7aeaf683-1d03-4f3c-9c4d-be4ed89d1f63",
   "metadata": {
    "tags": []
   },
   "source": [
    "def get_elbow(dataframe, index, min_clust, sample, kneedle):\n",
    "    \n",
    "    #with some help from https://joernhees.de/blog/2015/08/26/scipy-hierarchical-clustering-and-dendrogram-tutorial/\n",
    "    \n",
    "    clusterer_best = hdbscan.HDBSCAN(\n",
    "        min_samples = sample,\n",
    "        min_cluster_size = min_clust,\n",
    "        gen_min_span_tree = True,\n",
    "        metric = 'euclidean',\n",
    "    ).fit(dataframe)\n",
    "    \n",
    "    label = clusterer_best.labels_\n",
    "    label_list = label.tolist()\n",
    "    \n",
    "    if -1 in label_list:\n",
    "        label_list.remove(-1)\n",
    "    \n",
    "    n_cluster = len(set(label_list))\n",
    "    \n",
    "    linkage = clusterer_best.single_linkage_tree_.to_pandas()\n",
    "    numpy_linkage = linkage.drop(columns=['parent']).to_numpy()\n",
    "    \n",
    "    dist = numpy_linkage[:, 2]\n",
    "    dist_rev = dist[::-1]\n",
    "    \n",
    "    if kneedle == -1:\n",
    "        dist_area = dist_rev[0:n_cluster]\n",
    "    else:\n",
    "        dist_area = dist_rev[0:kneedle]\n",
    "    \n",
    "    idxs = np.arange(1, len(dist_area) + 1)\n",
    "\n",
    "    kn = KneeLocator(idxs, dist_area,\n",
    "        curve='convex',\n",
    "        direction='decreasing',\n",
    "        interp_method='polynomial',\n",
    "        online=True,\n",
    "        S = 1.0,\n",
    "    )\n",
    "    \n",
    "    n_cluster_raw = kn.knee\n",
    "    n_cluster_norm = kn.norm_knee\n",
    "    \n",
    "    #linkage.set_index('parent', inplace = True)\n",
    "    elbow = pd.DataFrame({'n_cluster': idxs, \n",
    "                          'distance': dist_area, \n",
    "                          'x_normalized':kn.x_normalized, \n",
    "                          'y_normalized':kn.y_normalized, \n",
    "                          'x_difference':kn.x_difference, \n",
    "                          'y_difference':kn.y_difference}).set_index('n_cluster')\n",
    "    epsilon_best = elbow.loc[n_cluster_raw][['distance']].item()\n",
    "    linkage.set_index('parent', inplace = True)\n",
    "    \n",
    "    return(linkage, elbow, epsilon_best, n_cluster_raw, n_cluster_norm)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "76cc2df0-3770-4778-a576-eca2a198bc6d",
   "metadata": {
    "tags": []
   },
   "source": [
    "def get_cluster(epsilon_best, dataframe, accession, min_clust, sample):\n",
    "    \n",
    "    clusterer_best = hdbscan.HDBSCAN(\n",
    "        min_samples = sample,\n",
    "        min_cluster_size = min_clust,\n",
    "        cluster_selection_epsilon = epsilon_best,\n",
    "        gen_min_span_tree=True,\n",
    "        metric = 'euclidean',\n",
    "    ).fit(dataframe)\n",
    "\n",
    "    label = clusterer_best.labels_\n",
    "    label_list = label.tolist()\n",
    "    \n",
    "    unclustered = label_list.count(-1)\n",
    "    label_set = set(label_list)\n",
    "    \n",
    "    if -1 in label_set:\n",
    "        label_set.remove(-1)\n",
    "    \n",
    "    n_cluster = len(label_set)\n",
    "    \n",
    "    cluster = pd.DataFrame(zip(index, label), columns = ['accession', 'cluster']).set_index('accession')\n",
    "    \n",
    "    return(cluster, n_cluster, unclustered)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "1a6b0fe5-6dd6-4bf7-a705-83b9711748c9",
   "metadata": {
    "tags": []
   },
   "source": [
    "epsilon_best"
   ]
  },
  {
   "cell_type": "raw",
   "id": "59f39703-9629-44f0-94fd-512d26c218bc",
   "metadata": {
    "tags": []
   },
   "source": [
    "cluster, n_cluster, unclustered = get_cluster(epsilon_best, matrixl2, index, min_clust, 2)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "18c1a533-be86-44af-a53a-b3280442e07e",
   "metadata": {
    "tags": []
   },
   "source": [
    "print(n_cluster, unclustered)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "7ec2359f-8cb5-4ff7-a1ee-ee0b67cf3b7b",
   "metadata": {
    "tags": []
   },
   "source": [
    "cluster.to_csv('cluster.csv', index=True, header=True, sep=',', mode='w')\n",
    "linkage.to_csv('linkage.csv', index=True, header=True, sep=',', mode='w')"
   ]
  },
  {
   "cell_type": "raw",
   "id": "8259a63b-7307-4536-81e6-179712b61865",
   "metadata": {
    "tags": []
   },
   "source": [
    "pd.DataFrame(matrixl2, index = index).to_csv('matrixl2.csv', index=True, header=True, sep=',', mode='w')"
   ]
  },
  {
   "cell_type": "raw",
   "id": "4a6c4649-f324-4a88-80f8-f0c40020ad49",
   "metadata": {
    "tags": []
   },
   "source": [
    "#linkage, elbow, epsilon_best, n_cluster_raw, n_cluster_norm = get_elbow(matrixl2, index, min_clust, sample, kneedle)\n",
    "epsilon_best = get_elbow2(matrixl2)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "58b9d118-199c-4ab9-8c89-a2fd353e6fb4",
   "metadata": {
    "tags": []
   },
   "source": [
    "def get_elbow2(matrixl2):\n",
    "\n",
    "    nearest_neighbors = NearestNeighbors(n_neighbors=11)\n",
    "    neighbors = nearest_neighbors.fit(matrixl2)\n",
    "    distances, indices = neighbors.kneighbors(matrixl2)\n",
    "\n",
    "    distances = np.sort(distances[:,10], axis=0)\n",
    "    i = np.arange(len(distances))\n",
    "    knee = KneeLocator(i, distances, S=10, curve='convex', direction='increasing', interp_method='polynomial')\n",
    "    knee.plot_knee()\n",
    "    \n",
    "    return(distances[knee.knee].item())"
   ]
  },
  {
   "cell_type": "raw",
   "id": "6280c61b-dd2b-4443-8c25-bf561490a3cb",
   "metadata": {},
   "source": [
    "kimura = {\n",
    "    'A':{'A':state, 'C':beta, 'G':alpha, 'T':beta,},\n",
    "    'C':{'A':beta, 'C':state, 'G':beta, 'T':alpha,},\n",
    "    'G':{'A':alpha, 'C':beta, 'G':state, 'T':beta,},\n",
    "    'T':{'A':beta, 'C':alpha, 'G':beta, 'T':state,},\n",
    "}"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a86d5eed-e977-4790-b677-5740e938fde1",
   "metadata": {},
   "source": [
    "next(map(lambda x: kimura[x], ['A', 'C', 'G', 'T']))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b57adc96-b0a4-4951-8c38-ea22a8686ca5",
   "metadata": {},
   "source": [
    "map(lambda x: x*2, [1, 2, 3])"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a746ea59-3253-402a-b6c5-b59f958ae69e",
   "metadata": {},
   "source": [
    "next(map(lambda x: x*2, [1, 2, 3]))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "052d6015-4423-449e-8b8e-6dc1626a1c46",
   "metadata": {},
   "source": [
    "for i in range(len(sequence) - self.k + 1):\n",
    "kmer = sequence[i:i+self.k]"
   ]
  },
  {
   "cell_type": "raw",
   "id": "5aea751e-4f62-4b3f-a275-2c2d456ff022",
   "metadata": {},
   "source": [
    "def split_seq(seq,size):\n",
    "    \"\"\" Split up seq in pieces of size \"\"\"\n",
    "    return [seq[i:i+size] for i in range(0, len(seq), size)]\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

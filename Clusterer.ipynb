{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "79d8651b-5274-4fc6-ab22-176f456fa406",
   "metadata": {
    "tags": []
   },
   "source": [
    "# K-mer Evolution Notebook\n",
    "\n",
    "- HDBSCAN github errors!\n",
    "    - need to find version without problems\n",
    "    - if now finding one revert back to MA version\n",
    "- better inclusion of R, N, ... in the kmer\n",
    "    - status: finished\n",
    "- evolution on reading frame\n",
    "    - difficult, ORF notebook necessary for it\n",
    "- status: unfinished\n",
    "\n",
    "![Class](Clusterer.svg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "renewable-pledge",
   "metadata": {},
   "outputs": [],
   "source": [
    "from kneed import DataGenerator, KneeLocator\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import itertools as it\n",
    "from Bio import SeqIO\n",
    "from Bio.Seq import Seq\n",
    "import math\n",
    "import re\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.decomposition import PCA\n",
    "import hdbscan\n",
    "from scipy.signal import savgol_filter\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2a2b792e-80db-4f31-8085-18ea98ac84ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 7 \n",
    "split = '|' \n",
    "string = ['4', 'Pass'] \n",
    "position = [2, 8] \n",
    "variable = 0.9\n",
    "min_clust = 2\n",
    "sample = 1\n",
    "num_clust =  60\n",
    "n_components = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "noticed-pitch",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Vectors(object):\n",
    "    \n",
    "    def __init__(self, k = 7, split = None, string = [''], position = [0], variable = 0.9):\n",
    "    \n",
    "        self.k = k\n",
    "        self.position = position\n",
    "        self.split = split\n",
    "        self.string = string\n",
    "        self.variable = variable\n",
    "        self.nucleotides = ['A', 'C', 'G', 'T']\n",
    "        self.substit = dict.fromkeys(map(ord, self.nucleotides), None)\n",
    "        self.exist = dict.fromkeys(map(''.join, it.product(self.nucleotides, repeat = self.k)), 0)        \n",
    "        self.col = len(self.exist.keys())\n",
    "        \n",
    "        self.amino = {\n",
    "            'AAA':'K', 'AAC':'N', 'AAG':'K', 'AAT':'N',\n",
    "            'ACA':'T', 'ACC':'T', 'ACG':'T', 'ACT':'T',\n",
    "            'AGA':'R', 'AGC':'S', 'AGG':'R', 'AGT':'S',\n",
    "            'ATA':'I', 'ATC':'I', 'ATG':'M', 'ATT':'I',\n",
    "            'CAA':'Q', 'CAC':'H', 'CAG':'Q', 'CAT':'H',\n",
    "            'CCA':'P', 'CCC':'P', 'CCG':'P', 'CCT':'P',\n",
    "            'CGA':'R', 'CGC':'R', 'CGG':'R', 'CGT':'R',\n",
    "            'CTA':'L', 'CTC':'L', 'CTG':'L', 'CTT':'L',\n",
    "            'GAA':'E', 'GAC':'D', 'GAG':'E', 'GAT':'D',\n",
    "            'GCA':'A', 'GCC':'A', 'GCG':'A', 'GCT':'A',\n",
    "            'GGA':'G', 'GGC':'G', 'GGG':'G', 'GGT':'G',\n",
    "            'GTA':'V', 'GTC':'V', 'GTG':'V', 'GTT':'V',    \n",
    "            'TAA':'Y', 'TAC':'*', 'TAG':'*', 'TAT':'Y',\n",
    "            'TCA':'S', 'TCC':'S', 'TCG':'S', 'TCT':'S',\n",
    "            'TGA':'*', 'TGC':'C', 'TGG':'W', 'TGT':'C',\n",
    "            'TTA':'L', 'TTC':'F', 'TTG':'L', 'TTT':'F',\n",
    "        }\n",
    "        self.nucex = {\n",
    "            'A':['A'],\n",
    "            'C':['C'],\n",
    "            'G':['G'],\n",
    "            'T':['T'],\n",
    "            'R':['A', 'G'],\n",
    "            'Y':['C', 'T'],\n",
    "            'W':['A', 'T'],\n",
    "            'S':['C', 'G'],\n",
    "            'M':['A', 'C'],\n",
    "            'K':['G', 'T'],\n",
    "            'B':['G', 'C', 'T'],\n",
    "            'H':['A', 'C', 'T'],\n",
    "            'D':['A', 'G', 'T'],\n",
    "            'V':['A', 'C', 'G'],\n",
    "            'N':['A', 'C', 'G', 'T'],\n",
    "        } \n",
    "        self.nucmut = {\n",
    "            'A':['C', 'G', 'T'],\n",
    "            'C':['A', 'G', 'T'],\n",
    "            'G':['A', 'C', 'T'],\n",
    "            'T':['A', 'C', 'G'],\n",
    "        } \n",
    "    \n",
    "    def checkup(self, head):\n",
    "        \n",
    "        try:\n",
    "            return(all([re.match(i[0], head[i[1]], re.IGNORECASE) for i in zip(self.string, self.position)]))\n",
    "        except:\n",
    "            return(False)\n",
    "            \n",
    "    def countRows(self, infile):\n",
    "        \n",
    "        row = 0\n",
    "        for entry in SeqIO.parse(infile,'fasta'):\n",
    "            \n",
    "            name = entry.name\n",
    "            head = name.split(self.split)\n",
    "            sequence = str(entry.seq)\n",
    "            missing = len(sequence.translate(self.substit))\n",
    "            fracture = float(len(sequence)/missing) if missing else 0 \n",
    "            \n",
    "            if self.checkup(head) == True and fracture <= self.variable:\n",
    "                row += 1\n",
    "                \n",
    "        return(row)\n",
    "    \n",
    "    def calculateFrequence(self, infile):\n",
    "        \n",
    "        row = self.countRows(infile)\n",
    "        index = np.empty(row, dtype = 'object')\n",
    "        matrix = np.empty((row, self.col, ),dtype = 'float32')\n",
    "        \n",
    "        pos = 0\n",
    "        for entry in SeqIO.parse(infile,'fasta'):\n",
    "            \n",
    "            name = entry.name\n",
    "            head = name.split(self.split)\n",
    "            sequence = str(entry.seq)\n",
    "            missing = len(sequence.translate(self.substit))\n",
    "            fracture = float(len(sequence)/missing) if missing else 0 \n",
    "            \n",
    "            if self.checkup(head) == True and fracture <= self.variable:\n",
    "                for i in range(len(sequence) - self.k + 1):\n",
    "                    \n",
    "                    kmer = sequence[i:i+self.k]\n",
    "                    \n",
    "                    if fracture == 0:\n",
    "                        main = [kmer]\n",
    "                        size = 1\n",
    "                    else:\n",
    "                        main = map(''.join, it.product(*[self.nucex.get(j) for j in kmer]))\n",
    "                        size = np.prod([len(self.nucex.get(k)) for k in kmer])\n",
    "                        \n",
    "                    for sub in main:\n",
    "                        self.exist[sub] += float(1/size)\n",
    "                    #    self.exist[sub] += float((1-self.mutfac)/size)     \n",
    "                    #    for l, nuc in enumerate(sub):\n",
    "                    #        for mutation in map(''.join, it.product(*[[sub[:l]], self.nucmut.get(nuc), [sub[l+1:]]])):\n",
    "                    #            self.exist[mutation] += float(self.mutfac/(size*12))\n",
    "\n",
    "                matrix[pos] = np.fromiter(self.exist.values(), dtype = 'float32', count = self.col)/sum(self.exist.values())\n",
    "                index[pos] = head[0]\n",
    "                \n",
    "                self.exist.update((k,0) for k in self.exist.keys())\n",
    "                pos += 1\n",
    "            \n",
    "        return(index, matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6afb4be1-5c98-4a74-baf2-991f0b2e0225",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Cluster(linkage, min_clust, num_clust):\n",
    "\n",
    "    x = 0.0\n",
    "    y = 1.0\n",
    "    cluster = linkage.get_clusters(cut_distance = x, min_cluster_size = min_clust)\n",
    "    n = cluster.max().item()\n",
    "\n",
    "    while n != num_clust:\n",
    "\n",
    "        if n < num_clust and n != -1:\n",
    "            x = x - y\n",
    "            y = y * 0.1\n",
    "\n",
    "        else:\n",
    "            x = x + y\n",
    "\n",
    "        cluster = linkage.get_clusters(cut_distance = x, min_cluster_size = min_clust)\n",
    "        n = cluster.max().item()\n",
    "        \n",
    "    return(cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "harmful-tuesday",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectors = Vectors(k = k, split = split, string = string, position = position, variable = variable)\n",
    "index, matrixl1 = vectors.calculateFrequence('A.fasta')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "illegal-shannon",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components = n_components)\n",
    "matrixpca = pca.fit_transform(matrixl1)\n",
    "variance = pca.explained_variance_ratio_.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "collected-resident",
   "metadata": {},
   "outputs": [],
   "source": [
    "matrixl2 = normalize(matrixpca, norm='l2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d0639f84-5901-44cb-93de-0703cbdfca64",
   "metadata": {},
   "outputs": [],
   "source": [
    "hdbinit = hdbscan.HDBSCAN(min_samples = sample, min_cluster_size = min_clust, gen_min_span_tree = True, metric = 'euclidean').fit(matrixl2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7616dc58-1b79-4bae-90ca-16af921fff5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "linkage = hdbinit.single_linkage_tree_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "35ab2f30-1f20-43bc-a72a-6ed9239f36ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster = Cluster(linkage, min_clust, num_clust)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "0b0aaefe-1a24-4829-84dc-b9154de87cac",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(zip(index, cluster), columns = ['accession', 'cluster']).set_index('accession').to_csv('cluster.csv', index=True, header=True, sep=',', mode='w')\n",
    "linkage.to_pandas().set_index('parent', inplace = False).to_csv('linkage.csv', index=True, header=True, sep=',', mode='w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fe0a0ac-d70f-489a-815f-8b8b9b349046",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92d59a13-244f-4815-b158-7683402fa6a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "439b8ec7-0c36-47c1-af73-d34e833cd8b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67a1cb2f-03f9-4662-93d7-c0e88ba6b951",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "id": "7aeaf683-1d03-4f3c-9c4d-be4ed89d1f63",
   "metadata": {},
   "source": [
    "def get_elbow(dataframe, index, min_clust, sample, kneedle):\n",
    "    \n",
    "    #with some help from https://joernhees.de/blog/2015/08/26/scipy-hierarchical-clustering-and-dendrogram-tutorial/\n",
    "    \n",
    "    clusterer_best = hdbscan.HDBSCAN(\n",
    "        min_samples = sample,\n",
    "        min_cluster_size = min_clust,\n",
    "        gen_min_span_tree = True,\n",
    "        metric = 'euclidean',\n",
    "    ).fit(dataframe)\n",
    "    \n",
    "    label = clusterer_best.labels_\n",
    "    label_list = label.tolist()\n",
    "    \n",
    "    if -1 in label_list:\n",
    "        label_list.remove(-1)\n",
    "    \n",
    "    n_cluster = len(set(label_list))\n",
    "    \n",
    "    linkage = clusterer_best.single_linkage_tree_.to_pandas()\n",
    "    numpy_linkage = linkage.drop(columns=['parent']).to_numpy()\n",
    "    \n",
    "    dist = numpy_linkage[:, 2]\n",
    "    dist_rev = dist[::-1]\n",
    "    \n",
    "    if kneedle == -1:\n",
    "        dist_area = dist_rev[0:n_cluster]\n",
    "    else:\n",
    "        dist_area = dist_rev[0:kneedle]\n",
    "    \n",
    "    idxs = np.arange(1, len(dist_area) + 1)\n",
    "\n",
    "    kn = KneeLocator(idxs, dist_area,\n",
    "        curve='convex',\n",
    "        direction='decreasing',\n",
    "        interp_method='polynomial',\n",
    "        online=True,\n",
    "        S = 1.0,\n",
    "    )\n",
    "    \n",
    "    n_cluster_raw = kn.knee\n",
    "    n_cluster_norm = kn.norm_knee\n",
    "    \n",
    "    #linkage.set_index('parent', inplace = True)\n",
    "    elbow = pd.DataFrame({'n_cluster': idxs, \n",
    "                          'distance': dist_area, \n",
    "                          'x_normalized':kn.x_normalized, \n",
    "                          'y_normalized':kn.y_normalized, \n",
    "                          'x_difference':kn.x_difference, \n",
    "                          'y_difference':kn.y_difference}).set_index('n_cluster')\n",
    "    epsilon_best = elbow.loc[n_cluster_raw][['distance']].item()\n",
    "    linkage.set_index('parent', inplace = True)\n",
    "    \n",
    "    return(linkage, elbow, epsilon_best, n_cluster_raw, n_cluster_norm)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "76cc2df0-3770-4778-a576-eca2a198bc6d",
   "metadata": {},
   "source": [
    "def get_cluster(epsilon_best, dataframe, accession, min_clust, sample):\n",
    "    \n",
    "    clusterer_best = hdbscan.HDBSCAN(\n",
    "        min_samples = sample,\n",
    "        min_cluster_size = min_clust,\n",
    "        cluster_selection_epsilon = epsilon_best,\n",
    "        gen_min_span_tree=True,\n",
    "        metric = 'euclidean',\n",
    "    ).fit(dataframe)\n",
    "\n",
    "    label = clusterer_best.labels_\n",
    "    label_list = label.tolist()\n",
    "    \n",
    "    unclustered = label_list.count(-1)\n",
    "    label_set = set(label_list)\n",
    "    \n",
    "    if -1 in label_set:\n",
    "        label_set.remove(-1)\n",
    "    \n",
    "    n_cluster = len(label_set)\n",
    "    \n",
    "    cluster = pd.DataFrame(zip(index, label), columns = ['accession', 'cluster']).set_index('accession')\n",
    "    \n",
    "    return(cluster, n_cluster, unclustered)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "1a6b0fe5-6dd6-4bf7-a705-83b9711748c9",
   "metadata": {},
   "source": [
    "epsilon_best"
   ]
  },
  {
   "cell_type": "raw",
   "id": "59f39703-9629-44f0-94fd-512d26c218bc",
   "metadata": {},
   "source": [
    "cluster, n_cluster, unclustered = get_cluster(epsilon_best, matrixl2, index, min_clust, 2)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "18c1a533-be86-44af-a53a-b3280442e07e",
   "metadata": {},
   "source": [
    "print(n_cluster, unclustered)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "7ec2359f-8cb5-4ff7-a1ee-ee0b67cf3b7b",
   "metadata": {},
   "source": [
    "cluster.to_csv('cluster.csv', index=True, header=True, sep=',', mode='w')\n",
    "linkage.to_csv('linkage.csv', index=True, header=True, sep=',', mode='w')"
   ]
  },
  {
   "cell_type": "raw",
   "id": "8259a63b-7307-4536-81e6-179712b61865",
   "metadata": {},
   "source": [
    "pd.DataFrame(matrixl2, index = index).to_csv('matrixl2.csv', index=True, header=True, sep=',', mode='w')"
   ]
  },
  {
   "cell_type": "raw",
   "id": "4a6c4649-f324-4a88-80f8-f0c40020ad49",
   "metadata": {},
   "source": [
    "#linkage, elbow, epsilon_best, n_cluster_raw, n_cluster_norm = get_elbow(matrixl2, index, min_clust, sample, kneedle)\n",
    "epsilon_best = get_elbow2(matrixl2)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "58b9d118-199c-4ab9-8c89-a2fd353e6fb4",
   "metadata": {},
   "source": [
    "def get_elbow2(matrixl2):\n",
    "\n",
    "    nearest_neighbors = NearestNeighbors(n_neighbors=11)\n",
    "    neighbors = nearest_neighbors.fit(matrixl2)\n",
    "    distances, indices = neighbors.kneighbors(matrixl2)\n",
    "\n",
    "    distances = np.sort(distances[:,10], axis=0)\n",
    "    i = np.arange(len(distances))\n",
    "    knee = KneeLocator(i, distances, S=10, curve='convex', direction='increasing', interp_method='polynomial')\n",
    "    knee.plot_knee()\n",
    "    \n",
    "    return(distances[knee.knee].item())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "79d8651b-5274-4fc6-ab22-176f456fa406",
   "metadata": {
    "tags": []
   },
   "source": [
    "# K-mer Evolution Notebook\n",
    "\n",
    "## Notes\n",
    "\n",
    "- HDBSCAN github errors!\n",
    "    - need to find version without problems\n",
    "    - if now finding one revert back to MA version\n",
    "- better inclusion of R, N, ... in the kmer\n",
    "    - status: finished\n",
    "- evolution on reading frame\n",
    "    - difficult, ORF notebook necessary for it\n",
    "- status: unfinished\n",
    "\n",
    "## Blueprint\n",
    "\n",
    "![Class](Clusterer.svg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "renewable-pledge",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import itertools as it\n",
    "from Bio import SeqIO\n",
    "from Bio.Seq import Seq\n",
    "import math\n",
    "import re\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.decomposition import PCA\n",
    "import multiprocessing as mp\n",
    "import hdbscan\n",
    "import progressbar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "2a2b792e-80db-4f31-8085-18ea98ac84ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 7 \n",
    "split = '|' \n",
    "quality = {'4':2, 'Pass':8}\n",
    "variable = 0.9\n",
    "min_clust = 2\n",
    "sample = 1\n",
    "num_clust =  60\n",
    "n_components = 50\n",
    "state = 1.0\n",
    "alpha = 0.05\n",
    "beta = 0.025"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "noticed-pitch",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Vectors(object):\n",
    "    \n",
    "    def __init__(self, k = 7, split = None, quality = {'':0}, variable = 0.9, state = 1.0, alpha = 0.05, beta = 0.025):\n",
    "    \n",
    "        self.k = k\n",
    "        self.quality = quality\n",
    "        self.split = split\n",
    "        self.variable = variable\n",
    "        self.nucleotides = ['A', 'C', 'G', 'T']\n",
    "        self.substit = dict.fromkeys(map(ord, self.nucleotides), None)\n",
    "        self.exist = dict.fromkeys(map(''.join, it.product(self.nucleotides, repeat = self.k)), 0)        \n",
    "        self.col = len(self.exist.keys())\n",
    "        self.state = state\n",
    "        self.nucex = {\n",
    "            'A':['A'],\n",
    "            'C':['C'],\n",
    "            'G':['G'],\n",
    "            'T':['T'],\n",
    "            'R':['A', 'G'],\n",
    "            'Y':['C', 'T'],\n",
    "            'W':['A', 'T'],\n",
    "            'S':['C', 'G'],\n",
    "            'M':['A', 'C'],\n",
    "            'K':['G', 'T'],\n",
    "            'B':['G', 'C', 'T'],\n",
    "            'H':['A', 'C', 'T'],\n",
    "            'D':['A', 'G', 'T'],\n",
    "            'V':['A', 'C', 'G'],\n",
    "            'N':['A', 'C', 'G', 'T'],\n",
    "        } \n",
    "        self.nucmut = {\n",
    "            'A':['C', 'G', 'T'],\n",
    "            'C':['A', 'G', 'T'],\n",
    "            'G':['A', 'C', 'T'],\n",
    "            'T':['A', 'C', 'G'],\n",
    "        } \n",
    "        self.nucval = {\n",
    "            ('A','C'):beta,\n",
    "            ('A','G'):alpha,\n",
    "            ('A','T'):beta,\n",
    "            ('C','A'):beta,\n",
    "            ('C','G'):beta,\n",
    "            ('C','T'):alpha,\n",
    "            ('G','A'):alpha,\n",
    "            ('G','C'):beta,\n",
    "            ('G','T'):beta,\n",
    "            ('T','A'):beta,\n",
    "            ('T','C'):alpha,\n",
    "            ('T','G'):beta,\n",
    "        }\n",
    "    \n",
    "    def countRows(self, infile):\n",
    "        \n",
    "        sequences = {}\n",
    "        index = []\n",
    "        row = 0\n",
    "        for entry in SeqIO.parse(infile,'fasta'):\n",
    "            \n",
    "            name = entry.name\n",
    "            head = name.split(self.split)\n",
    "            sequence = str(entry.seq)\n",
    "            missing = len(sequence.translate(self.substit))\n",
    "            fracture = float(len(sequence)/missing) if missing else 0 \n",
    "            accession = head[0]\n",
    "            \n",
    "            try:\n",
    "                if all([re.match(i, head[self.quality[i]], re.IGNORECASE) for i in self.quality]) == True and fracture <= self.variable:\n",
    "                    row += 1\n",
    "                    sequences[accession] = sequence\n",
    "                    index.append(accession)\n",
    "            except:\n",
    "                pass\n",
    "        \n",
    "        return(row, index, sequences)\n",
    "    \n",
    "    def calculateFrequence(self, infile):\n",
    "        \n",
    "        row, index, sequences = self.countRows(infile)\n",
    "        matrix = np.empty((row, self.col, ),dtype = 'float32')\n",
    "        \n",
    "        pos = 0\n",
    "        widgets = [' [', progressbar.Timer(format = 'elapsed time: %(elapsed)s'), '] ', progressbar.Bar('#'),' (', progressbar.ETA(), ') ', ]\n",
    "        bar = progressbar.ProgressBar(max_value = len(index), widgets = widgets).start()\n",
    "\n",
    "        for accession in index:\n",
    "            \n",
    "            sequence = sequences[accession]\n",
    "            for i in range(len(sequence) - self.k + 1):\n",
    "                kmer = sequence[i:i+self.k]\n",
    "                main = map(''.join, it.product(*[self.nucex.get(j) for j in kmer]))\n",
    "\n",
    "                for sub in main:\n",
    "                    self.exist[sub] += self.state\n",
    "                    for l, nuc in enumerate(sub):\n",
    "                        for mut in self.nucmut[nuc]:\n",
    "                            mutation = sub[:l] + mut + sub[l+1:]\n",
    "                            self.exist[mutation] += self.nucval[(nuc,mut)]\n",
    "\n",
    "            matrix[pos] = np.fromiter(self.exist.values(), dtype = 'float32', count = self.col)/sum(self.exist.values())\n",
    "            \n",
    "            self.exist.update((k,0) for k in self.exist.keys())\n",
    "            bar.update(pos)\n",
    "            pos += 1\n",
    "\n",
    "        bar.finish()\n",
    "\n",
    "        return(index, matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "6afb4be1-5c98-4a74-baf2-991f0b2e0225",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Cluster(linkage, min_clust, num_clust):\n",
    "\n",
    "    x = 0.0\n",
    "    y = 1.0\n",
    "    cluster = linkage.get_clusters(cut_distance = x, min_cluster_size = min_clust)\n",
    "    n = cluster.max().item()\n",
    "\n",
    "    while n != num_clust:\n",
    "\n",
    "        if n < num_clust and n != -1:\n",
    "            x = x - y\n",
    "            y = y * 0.1\n",
    "\n",
    "        else:\n",
    "            x = x + y\n",
    "\n",
    "        cluster = linkage.get_clusters(cut_distance = x, min_cluster_size = min_clust)\n",
    "        n = cluster.max().item()\n",
    "        \n",
    "    return(cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "harmful-tuesday",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " [elapsed time: 0:00:00] |##################################| (Time:  0:00:00) \n"
     ]
    }
   ],
   "source": [
    "vectors = Vectors(k = k, split = split, quality = quality, variable = variable, state = state, alpha = alpha, beta = beta) #FASTER it can still be faster\n",
    "index, matrixl1 = vectors.calculateFrequence('C.fasta')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "illegal-shannon",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components = 50)\n",
    "matrixpca = pca.fit_transform(matrixl1)\n",
    "variance = pca.explained_variance_ratio_.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "collected-resident",
   "metadata": {},
   "outputs": [],
   "source": [
    "matrixl2 = normalize(matrixpca, norm='l2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "d0639f84-5901-44cb-93de-0703cbdfca64",
   "metadata": {},
   "outputs": [],
   "source": [
    "hdbinit = hdbscan.HDBSCAN(min_samples = sample, min_cluster_size = min_clust, gen_min_span_tree = True, metric = 'euclidean').fit(matrixl2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "7616dc58-1b79-4bae-90ca-16af921fff5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "linkage = hdbinit.single_linkage_tree_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "1bff8f94-97bd-46e4-a70b-d7bfa96527cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster = Cluster(linkage, min_clust, num_clust) #error correction ergÃ¤nzen, wenn er die Zahl nicht finden kann (kleine Stickprobe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "f6f0be50-63c3-4ead-b869-7bf6a14931e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "framecl = pd.DataFrame(zip(index, cluster), columns = ['accession', 'cluster']).set_index('accession')\n",
    "framelk = linkage.to_pandas().set_index('parent', inplace = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "0b0aaefe-1a24-4829-84dc-b9154de87cac",
   "metadata": {},
   "outputs": [],
   "source": [
    "framecl.to_csv('cluster.csv', index=True, header=True, sep=',', mode='w')\n",
    "framelk.to_csv('linkage.csv', index=True, header=True, sep=',', mode='w')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "625db32a-1deb-4ed2-a5f8-0f1bfdcfef57",
   "metadata": {},
   "source": [
    "## Garbage Place"
   ]
  },
  {
   "cell_type": "raw",
   "id": "5697df5a-f35c-43de-8ddc-9a73fca5c02a",
   "metadata": {},
   "source": [
    "from itertools import repeat\n",
    "import multiprocessing as mp\n",
    "import os\n",
    "import pprint\n",
    "\n",
    "def f(d: dict) -> None:\n",
    "    pid = os.getpid()\n",
    "    d[pid] = \"Hi, I was written by process %d\" % pid\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    with mp.Manager() as manager:\n",
    "        d = manager.dict()\n",
    "        with manager.Pool() as pool:\n",
    "            pool.map(f, repeat(d, 10))\n",
    "        # `d` is a DictProxy object that can be converted to dict\n",
    "        pprint.pprint(dict(d))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "82913ae1-85fa-4ac1-bd51-6bd30973bd94",
   "metadata": {},
   "source": [
    "def calculateFragment(self, accession):\n",
    "        \n",
    "        sequence = self.sequences[accession]\n",
    "        for i in range(len(sequence) - self.k + 1):\n",
    "\n",
    "            kmer = sequence[i:i+self.k]\n",
    "            main = map(''.join, it.product(*[self.nucex.get(j) for j in kmer]))\n",
    "\n",
    "            for sub in main:\n",
    "                self.exist[sub] += self.state\n",
    "                for l, nuc in enumerate(sub):\n",
    "                    for mut in self.nucmut[nuc]:\n",
    "                        mutation = sub[:l] + mut + sub[l+1:]\n",
    "                        self.exist[mutation] += self.nucval[(nuc,mut)]\n",
    "\n",
    "        vector = np.fromiter(self.exist.values(), dtype = 'float32', count = self.col)/sum(self.exist.values())\n",
    "        return(vector)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d1bf4682-7af0-4250-84e3-ca9f6382b26e",
   "metadata": {},
   "source": [
    "#from kneed import DataGenerator, KneeLocator\n",
    "#import matplotlib.pyplot as plt\n",
    "\n",
    "#from scipy.signal import savgol_filter\n",
    "#from sklearn.neighbors import NearestNeighbors\n",
    "#import networkx as nx"
   ]
  },
  {
   "cell_type": "raw",
   "id": "0a0cbb5c-2265-4d07-9b8d-b59486d7c4b9",
   "metadata": {},
   "source": [
    "                #    size = np.prod([len(self.nucex.get(k)) for k in kmer])\n",
    "                # for sub in main:\n",
    "                #    self.exist[sub] += float(1/size)\n",
    "                #    self.exist[sub] += float((1-self.mutfac)/size)     \n",
    "                #    for l, nuc in enumerate(sub):\n",
    "                #        for mutation in map(''.join, it.product(*[[sub[:l]], self.nucmut.get(nuc), [sub[l+1:]]])):\n",
    "                #            self.exist[mutation] += float(self.mutfac/(size*12))\n",
    "                #        for mutation in map(''.join, it.product(*[[sub[:l]], self.nucmut.get(nuc), [sub[l+1:]]])):\n",
    "                #            self.exist[mutation] += self.nucval[(nuc,mutation[l])]"
   ]
  },
  {
   "cell_type": "raw",
   "id": "7aeaf683-1d03-4f3c-9c4d-be4ed89d1f63",
   "metadata": {},
   "source": [
    "def get_elbow(dataframe, index, min_clust, sample, kneedle):\n",
    "    \n",
    "    #with some help from https://joernhees.de/blog/2015/08/26/scipy-hierarchical-clustering-and-dendrogram-tutorial/\n",
    "    \n",
    "    clusterer_best = hdbscan.HDBSCAN(\n",
    "        min_samples = sample,\n",
    "        min_cluster_size = min_clust,\n",
    "        gen_min_span_tree = True,\n",
    "        metric = 'euclidean',\n",
    "    ).fit(dataframe)\n",
    "    \n",
    "    label = clusterer_best.labels_\n",
    "    label_list = label.tolist()\n",
    "    \n",
    "    if -1 in label_list:\n",
    "        label_list.remove(-1)\n",
    "    \n",
    "    n_cluster = len(set(label_list))\n",
    "    \n",
    "    linkage = clusterer_best.single_linkage_tree_.to_pandas()\n",
    "    numpy_linkage = linkage.drop(columns=['parent']).to_numpy()\n",
    "    \n",
    "    dist = numpy_linkage[:, 2]\n",
    "    dist_rev = dist[::-1]\n",
    "    \n",
    "    if kneedle == -1:\n",
    "        dist_area = dist_rev[0:n_cluster]\n",
    "    else:\n",
    "        dist_area = dist_rev[0:kneedle]\n",
    "    \n",
    "    idxs = np.arange(1, len(dist_area) + 1)\n",
    "\n",
    "    kn = KneeLocator(idxs, dist_area,\n",
    "        curve='convex',\n",
    "        direction='decreasing',\n",
    "        interp_method='polynomial',\n",
    "        online=True,\n",
    "        S = 1.0,\n",
    "    )\n",
    "    \n",
    "    n_cluster_raw = kn.knee\n",
    "    n_cluster_norm = kn.norm_knee\n",
    "    \n",
    "    #linkage.set_index('parent', inplace = True)\n",
    "    elbow = pd.DataFrame({'n_cluster': idxs, \n",
    "                          'distance': dist_area, \n",
    "                          'x_normalized':kn.x_normalized, \n",
    "                          'y_normalized':kn.y_normalized, \n",
    "                          'x_difference':kn.x_difference, \n",
    "                          'y_difference':kn.y_difference}).set_index('n_cluster')\n",
    "    epsilon_best = elbow.loc[n_cluster_raw][['distance']].item()\n",
    "    linkage.set_index('parent', inplace = True)\n",
    "    \n",
    "    return(linkage, elbow, epsilon_best, n_cluster_raw, n_cluster_norm)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "76cc2df0-3770-4778-a576-eca2a198bc6d",
   "metadata": {},
   "source": [
    "def get_cluster(epsilon_best, dataframe, accession, min_clust, sample):\n",
    "    \n",
    "    clusterer_best = hdbscan.HDBSCAN(\n",
    "        min_samples = sample,\n",
    "        min_cluster_size = min_clust,\n",
    "        cluster_selection_epsilon = epsilon_best,\n",
    "        gen_min_span_tree=True,\n",
    "        metric = 'euclidean',\n",
    "    ).fit(dataframe)\n",
    "\n",
    "    label = clusterer_best.labels_\n",
    "    label_list = label.tolist()\n",
    "    \n",
    "    unclustered = label_list.count(-1)\n",
    "    label_set = set(label_list)\n",
    "    \n",
    "    if -1 in label_set:\n",
    "        label_set.remove(-1)\n",
    "    \n",
    "    n_cluster = len(label_set)\n",
    "    \n",
    "    cluster = pd.DataFrame(zip(index, label), columns = ['accession', 'cluster']).set_index('accession')\n",
    "    \n",
    "    return(cluster, n_cluster, unclustered)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "1a6b0fe5-6dd6-4bf7-a705-83b9711748c9",
   "metadata": {},
   "source": [
    "epsilon_best"
   ]
  },
  {
   "cell_type": "raw",
   "id": "59f39703-9629-44f0-94fd-512d26c218bc",
   "metadata": {},
   "source": [
    "cluster, n_cluster, unclustered = get_cluster(epsilon_best, matrixl2, index, min_clust, 2)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "18c1a533-be86-44af-a53a-b3280442e07e",
   "metadata": {},
   "source": [
    "print(n_cluster, unclustered)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "7ec2359f-8cb5-4ff7-a1ee-ee0b67cf3b7b",
   "metadata": {},
   "source": [
    "cluster.to_csv('cluster.csv', index=True, header=True, sep=',', mode='w')\n",
    "linkage.to_csv('linkage.csv', index=True, header=True, sep=',', mode='w')"
   ]
  },
  {
   "cell_type": "raw",
   "id": "8259a63b-7307-4536-81e6-179712b61865",
   "metadata": {},
   "source": [
    "pd.DataFrame(matrixl2, index = index).to_csv('matrixl2.csv', index=True, header=True, sep=',', mode='w')"
   ]
  },
  {
   "cell_type": "raw",
   "id": "4a6c4649-f324-4a88-80f8-f0c40020ad49",
   "metadata": {},
   "source": [
    "#linkage, elbow, epsilon_best, n_cluster_raw, n_cluster_norm = get_elbow(matrixl2, index, min_clust, sample, kneedle)\n",
    "epsilon_best = get_elbow2(matrixl2)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "58b9d118-199c-4ab9-8c89-a2fd353e6fb4",
   "metadata": {},
   "source": [
    "def get_elbow2(matrixl2):\n",
    "\n",
    "    nearest_neighbors = NearestNeighbors(n_neighbors=11)\n",
    "    neighbors = nearest_neighbors.fit(matrixl2)\n",
    "    distances, indices = neighbors.kneighbors(matrixl2)\n",
    "\n",
    "    distances = np.sort(distances[:,10], axis=0)\n",
    "    i = np.arange(len(distances))\n",
    "    knee = KneeLocator(i, distances, S=10, curve='convex', direction='increasing', interp_method='polynomial')\n",
    "    knee.plot_knee()\n",
    "    \n",
    "    return(distances[knee.knee].item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5efce3db-6121-4bfd-8796-b649a8e66ca2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

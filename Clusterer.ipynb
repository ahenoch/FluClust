{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "79d8651b-5274-4fc6-ab22-176f456fa406",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Evolution including Virus Family hybrid Clustering based on artificially mutated K-mers\n",
    "\n",
    "## Milestones\n",
    "\n",
    "- [x] HDBSCAN github errors\n",
    "    - need to find version without problems\n",
    "    - if now finding one revert back to MA version\n",
    "    - revert back to Masterthesis and update jupyter lab, git and ressource\n",
    "- [x] better inclusion of R, N, ... in the kmer\n",
    "    - implemented, maybe need adjustment by value\n",
    "    - if frature of missing higher than threshold garbage\n",
    "    - if not fill missing by possible constellations\n",
    "- [x] evolution on reading frame\n",
    "    - difficult with amino conservation ORF tracker necessary\n",
    "        - e.g. BLOSUM etc.\n",
    "    - nucleotide exchange values used now, instead of amino exchange\n",
    "        - usage of Kimura's two-parameter model\n",
    "        - alpha and beta of user choice\n",
    "- [ ] stable parameters \n",
    "    - best would be algorithmic solution here\n",
    "        - number of clusters\n",
    "            - neighbors -> distance matrix -> kneedle algorithm -> epsilon\n",
    "        - sample number\n",
    "            - cluster number extraction algorithms -> sample \n",
    "    - alpha value (A -> G, C -> T)\n",
    "    - beta value (...)\n",
    "    - for more flexibility algorithmis solution was postponed to a later release\n",
    "\n",
    "- [x] global local hybrid clustering (GLHC)\n",
    "    - idea war rejected first due to the necessary nxn space in worst case\n",
    "    - maybe precalculation reinclude into clustering in the first place useful at some point\n",
    "        - precalculation: nxn\n",
    "        - no precalculation: nxk \n",
    "        - could be usefull in the future to change to precalculation\n",
    "        - necessary for this step is the stepwise calculation of the precalc matrix\n",
    "            - d(acc1, acc2), d(acc1, acc3), d(acc1, acc4), ..., d(acc1, accn)\n",
    "            - d(acc2, ....) find a way to calculate the rest based on the first line\n",
    "    - all point cluster distance (apcd) instead of centroids\n",
    "    - centroids -> single linkage(centroids)\n",
    "        - difficulat to validate the quality of this method\n",
    "        - used method at the moment cluster -> centroids -> alignment -> nexus\n",
    "- [ ] k-mer implementation by taking only existing values into account\n",
    "    - copy and update the old code from the project\n",
    "    - changes in the k-mer calculation postponed!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0e43f69-8d14-4baf-bfa0-77576b87acfa",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Packages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceae35a8-25c7-4a91-ab88-3a24f33f0e7f",
   "metadata": {},
   "source": [
    "### Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b0081d0a-ccdf-4c29-aa82-654f54154c39",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import itertools as it\n",
    "from Bio import SeqIO\n",
    "import re\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.decomposition import PCA\n",
    "import multiprocessing as mp\n",
    "import hdbscan\n",
    "import scipy.spatial.distance as ssd\n",
    "from scipy.cluster import hierarchy\n",
    "from tqdm import tqdm\n",
    "from kneed import KneeLocator\n",
    "import scipy.signal as signal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a824f9c-f26e-4894-9231-1fe16b032637",
   "metadata": {},
   "source": [
    "### Alignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "08eff79a-35e8-42a6-bee1-147a4e9e3583",
   "metadata": {},
   "outputs": [],
   "source": [
    "from io import StringIO\n",
    "from Bio import AlignIO\n",
    "from Bio.Align.Applications import MafftCommandline\n",
    "from Bio.Phylo.Applications import RaxmlCommandline\n",
    "import glob\n",
    "import os\n",
    "#from IPython.display import display"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d490fa0-5589-4c97-b50a-234455ed43f9",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Classes and Definitions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a7c076d-0b64-4c42-8a77-569b8830b6e2",
   "metadata": {},
   "source": [
    "### Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "noticed-pitch",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Vectors(object):\n",
    "    \n",
    "    def __init__(self, k = 7, identifier = 0, split = None, quality = {'':0}, variable = 2, state = 1.0, alpha = 0.0, beta = 0.0, init = 0.0, procs = 4, preprocess = True):\n",
    "    \n",
    "        self.k = k\n",
    "        self.quality = quality\n",
    "        self.identifier = identifier\n",
    "        self.split = split\n",
    "        self.variable = variable\n",
    "        self.nucleotides = ['A', 'C', 'G', 'T']\n",
    "        self.purines = ['A', 'G']\n",
    "        self.pyrines = ['C', 'T']\n",
    "        self.exotics = ['R', 'Y', 'W', 'S', 'M', 'K', 'B', 'H', 'D', 'V', 'N']\n",
    "#        self.substit = dict.fromkeys(map(ord, self.nucleotides), None)\n",
    "#        self.exist = dict.fromkeys(map(''.join, it.product(self.nucleotides, repeat = self.k)), init)        \n",
    "        self.state = state\n",
    "        self.init = init\n",
    "        self.procs = procs\n",
    "        self.alpha = alpha\n",
    "        self.beta = beta\n",
    "        self.preprocess = preprocess\n",
    "        self.exchange = {\n",
    "            'A': ['A'],\n",
    "            'C': ['C'],\n",
    "            'G': ['G'],\n",
    "            'T': ['T'],\n",
    "            'R': ['A', 'G'],\n",
    "            'Y': ['C', 'T'],\n",
    "            'W': ['A', 'T'],\n",
    "            'S': ['C', 'G'],\n",
    "            'M': ['A', 'C'],\n",
    "            'K': ['G', 'T'],\n",
    "            'B': ['G', 'C', 'T'],\n",
    "            'H': ['A', 'C', 'T'],\n",
    "            'D': ['A', 'G', 'T'],\n",
    "            'V': ['A', 'C', 'G'],\n",
    "            'N': ['A', 'C', 'G', 'T'],\n",
    "        }\n",
    "        self.kimura = {}\n",
    "        for nuc in self.nucleotides:\n",
    "            self.kimura[nuc] = {}\n",
    "            if self.alpha != 0.0: \n",
    "                a = self.purines if nuc in self.purines else self.pyrines\n",
    "                pos = 0 if a.index(nuc) != 0 else 1\n",
    "                self.kimura[nuc][a[pos]] = self.alpha\n",
    "            if self.beta != 0.0:\n",
    "                b = self.purines if nuc not in self.purines else self.pyrines\n",
    "                self.kimura[nuc][b[0]] = self.beta\n",
    "                self.kimura[nuc][b[1]] = self.beta\n",
    "    \n",
    "    def countRows(self, infile):\n",
    "        \n",
    "        index = []\n",
    "        record = SeqIO.index(infile, \"fasta\", key_function = lambda entry: entry.split(self.split)[self.identifier] if type(self.identifier) == int else re.search('.*' + self.identifier + '([^|]+).*', entry)[1])\n",
    "        for accession in record.keys():\n",
    "            \n",
    "            entry = record[accession]\n",
    "            header = entry.description.split(self.split)\n",
    "            sequence = str(entry.seq)\n",
    "            #missing = len(sequence.translate(self.substit))\n",
    "            #fracture = float(len(sequence)/missing) if missing else 0 \n",
    "            missing = re.findall('['+''.join(self.exotics)+']+', sequence)\n",
    "            \n",
    "            try:\n",
    "                if all([re.match(i, header[self.quality[i]], re.IGNORECASE) for i in self.quality]) == True and (0 if not missing else len(max(missing, key=len))) <= self.variable:\n",
    "                #if all([re.match(i, header[self.quality[i]], re.IGNORECASE) for i in self.quality]) == True and fracture <= 0.9:\n",
    "                    index.append(accession)\n",
    "            except:\n",
    "                pass\n",
    "        \n",
    "        return(index, record)\n",
    "    \n",
    "    def preprocessKmer(self, sequence):\n",
    "        \n",
    "        exist = []\n",
    "        for i in range(len(sequence) - self.k + 1):\n",
    "            kmer = sequence[i:i+self.k]\n",
    "            main = list(map(''.join, it.product(*[self.exchange.get(j) for j in kmer])))\n",
    "\n",
    "            for sub in main:\n",
    "                exist.append(sub)\n",
    "                #if self.kimura:\n",
    "                #    for l, nuc in enumerate(sub):\n",
    "                #        for mut in self.kimura[nuc].keys():\n",
    "                #            mutation = sub[:l] + mut + sub[l+1:]\n",
    "                            #self.exist[sub] = 0\n",
    "                #            exist.append(mutation)\n",
    "\n",
    "        return(exist)\n",
    "    \n",
    "    def calculateKmer(self, data):\n",
    "        \n",
    "        temporary, sequence = data\n",
    "        \n",
    "        for i in range(len(sequence) - self.k + 1):\n",
    "            kmer = sequence[i:i+self.k]\n",
    "            main = list(map(''.join, it.product(*[self.exchange.get(j) for j in kmer])))\n",
    "\n",
    "            for sub in main:\n",
    "                temporary[sub] += self.state/len(main)\n",
    "                if self.kimura:\n",
    "                    for l, nuc in enumerate(sub):\n",
    "                        for mut in self.kimura[nuc].keys():\n",
    "                            mutation = sub[:l] + mut + sub[l+1:]\n",
    "                            if mutation in temporary:\n",
    "                                temporary[mutation] += self.kimura[nuc][mut]\n",
    "\n",
    "        vector = np.fromiter(temporary.values(), dtype = 'float32', count = len(temporary.keys()))/sum(temporary.values())\n",
    "        temporary.clear()\n",
    "        return(vector)\n",
    "        \n",
    "    def calculateFrequence(self, infile):\n",
    "        \n",
    "        index, record = self.countRows(infile)\n",
    "        #matrix = np.empty((len(index), self.col, ),dtype = 'float32')\n",
    "        \n",
    "        if self.preprocess == True:\n",
    "            with mp.Pool(self.procs) as pool:\n",
    "                preprocessor = tqdm(pool.imap(self.preprocessKmer, map(lambda m: str(record[m].seq), index)), total = len(index), desc=\"Preprocessing\")\n",
    "                exist = dict(sorted(dict.fromkeys(it.chain.from_iterable(preprocessor), self.init).items()))\n",
    "\n",
    "        else:\n",
    "            exist = dict.fromkeys(map(''.join, it.product(self.nucleotides, repeat = self.k)), self.init)    \n",
    "                \n",
    "        shared = it.repeat(exist,len(index))\n",
    "        \n",
    "        with mp.Pool(self.procs) as pool:\n",
    "            calculator = tqdm(pool.imap(self.calculateKmer, zip(shared, map(lambda m: str(record[m].seq), index))), total = len(index), desc=\"Calculation\")\n",
    "            matrix = np.fromiter(it.chain.from_iterable(calculator), dtype = 'float32', count = len(exist.keys()) * len(index))\n",
    "            matrix.shape = len(index), len(exist.keys())\n",
    "            #for pos, vector in enumerate(calculator):\n",
    "            #    matrix[pos] = vector\n",
    "                \n",
    "        return(index, matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eb81e31-253d-41d3-aebd-8e15971c31ec",
   "metadata": {},
   "source": [
    "- execution can still be faster ca. 15-20min for segment 4 is still slow, lul now its 2 at max\n",
    "    - inclusion of mutation increased the runtime by factor 5-10, nvm multipressing easy\n",
    "    - multiprocessing difficult to implement (dicts, fast calculation of single instances high overhang)\n",
    "- all mutations and all unkown kmers (including e.g. Ns) are counted with state or respective alpha beta\n",
    "    - maybe split value by their number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f2036936-f8f7-4413-a0fb-1ccb5e84d7d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def knee_location(linkage, t=50, p=0.5, sig=20):\n",
    "\n",
    "    numpy_linkage = linkage.drop(columns=['parent']).to_numpy()\n",
    "    \n",
    "    y = numpy_linkage[:, 2][::-1]\n",
    "    x = np.arange(1, len(y) + 1)\n",
    "\n",
    "    kn = KneeLocator(np.log(x), y,\n",
    "        curve='convex',\n",
    "        direction='decreasing',\n",
    "        interp_method=\"interp1d\",\n",
    "        #online=True,\n",
    "        #S = 1.0,\n",
    "    )\n",
    "\n",
    "    #kn.plot_knee_normalized()\n",
    "    #plt.savefig('difference.png')\n",
    "\n",
    "    a = pd.DataFrame(zip(x, y, kn.x_difference, kn.y_difference), columns = ['x', 'y', 'x_diff', 'y_diff'])\n",
    "    #b = kn.y_difference\n",
    "\n",
    "    window = signal.general_gaussian(t+1, p=p, sig=sig)\n",
    "    filtered = signal.fftconvolve(window, kn.y_difference)\n",
    "    filtered = (np.average(kn.y_difference) / np.average(filtered)) * filtered\n",
    "    filtered = np.roll(filtered, -25)\n",
    "\n",
    "    # determine the indices of the local maxima\n",
    "    max_ind = signal.argrelextrema(filtered[:-t], np.greater)\n",
    "\n",
    "    a['gauss'] = filtered[:-t]\n",
    "\n",
    "    #plt.subplot(1, 2, 1)\n",
    "    #plt.plot(kn.x_difference, kn.y_difference, color='r')\n",
    "    #plt.subplot(1, 2, 2)\n",
    "    #plt.plot(kn.x_difference, filtered[:-t], color='r')\n",
    "    #plt.tight_layout()\n",
    "    #plt.savefig('gaussian.png')\n",
    "\n",
    "    # get the actual values using these indices\n",
    "    r = kn.y_difference[max_ind]  # array([5, 3, 6])\n",
    "    \n",
    "    return(a, r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6afb4be1-5c98-4a74-baf2-991f0b2e0225",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Cluster(linkage, minclust, numclust, max_iter = 500):\n",
    "\n",
    "    x = 0.0\n",
    "    y = 1.0\n",
    "    z = 0.0\n",
    "    cluster = linkage.get_clusters(cut_distance = x, min_cluster_size = minclust)\n",
    "    n = cluster.max().item()\n",
    "\n",
    "    while n != numclust:\n",
    "\n",
    "        if n < numclust and n != -1:\n",
    "            z = x\n",
    "            x = x - y\n",
    "            y = y * 0.1\n",
    "\n",
    "        else:\n",
    "            z = x\n",
    "            x = x + y\n",
    "\n",
    "        cluster = linkage.get_clusters(cut_distance = x, min_cluster_size = minclust)\n",
    "        n = cluster.max().item()\n",
    "        \n",
    "        if x != 0.0 and n == -1:\n",
    "            cluster = linkage.get_clusters(cut_distance = z, min_cluster_size = minclust)\n",
    "            n = cluster.max().item()\n",
    "            print(f'Error: Value not reachable. Using {n} cluster.')\n",
    "            break\n",
    "            \n",
    "        if max_iter == 0:\n",
    "            cluster = linkage.get_clusters(cut_distance = x, min_cluster_size = minclust)\n",
    "            n = cluster.max().item()\n",
    "            print(f'Warning: Max iteration reached. Using {n} cluster.')\n",
    "            break\n",
    "            \n",
    "        max_iter = max_iter - 1\n",
    "        \n",
    "    return(cluster, n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e03007cf-0d79-469f-995d-d65dee6b885a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def workerCentroid(subtuple):\n",
    "    \n",
    "    subl2, i = subtuple\n",
    "    indexdist = subl2.index.tolist()\n",
    "    calcdist = map(lambda x: ssd.cdist([x[1]], subl2, 'euclidean').mean(), subl2.iterrows())\n",
    "    framedist = pd.DataFrame(np.fromiter(calcdist, dtype = 'float32', count = len(subl2)), index = indexdist)\n",
    "    return(framedist.idxmin().item(), i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "78ad410c-a55c-492e-9bbd-36d1c8842d89",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Centroid(framecluster, framel2):\n",
    "    \n",
    "    groups = framecluster.query('cluster != -1').groupby('cluster').groups\n",
    "    \n",
    "    with mp.Pool(procs) as pool:\n",
    "        result = pool.imap(workerCentroid, map(lambda match: (framel2.loc[groups[match]], match), groups.keys()))\n",
    "        centroid = pd.DataFrame(result, columns = ['accession', 'cluster']).set_index('accession')\n",
    "        \n",
    "    return(centroid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5056fe9c-1a70-42df-a2bd-6f023476dd03",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Linkage(framecentroid, framel2, procs):\n",
    "    \n",
    "    subl2 = framel2.loc[framecentroid.index.tolist()]\n",
    "    distance = ssd.cdist(subl2, subl2, 'euclidean')\n",
    "    linkage = hierarchy.linkage(distance, method = 'single', metric = 'euclidean')\n",
    "    \n",
    "    return(linkage, distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9b25b9ef-d5b2-432c-87bc-87e1e259fb3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fillGaps(frame):\n",
    "    \n",
    "    array = frame.unique()\n",
    "    array = array[array != '']\n",
    "    if len(array) == 1:\n",
    "        frame.replace('', array[0], inplace = True)\n",
    "        frame.fillna(array[0], inplace = True)\n",
    "    else:\n",
    "        frame.replace('', 'na', inplace = True)\n",
    "        frame.fillna('na', inplace = True)\n",
    "        #changed to mixed from NA good decision?\n",
    "        \n",
    "    return(frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "576cc8c9-1607-4080-9e5e-b9970cb96129",
   "metadata": {},
   "outputs": [],
   "source": [
    "def curateFASTA(infile, split, identifier = 0, columns = {'':1}):\n",
    "    \n",
    "    meta = {ident:{} for ident in columns.keys()}\n",
    "    \n",
    "    for entry in SeqIO.parse(infile,'fasta'):\n",
    "    \n",
    "        header = entry.description.split(split)\n",
    "\n",
    "        accession = header[identifier] if type(identifier) == int else re.search('.*' + acc_ident + '([^|]+).*', entry.description)[1]\n",
    "        \n",
    "        for key in columns.keys():\n",
    "\n",
    "            position = columns[key]\n",
    "            try:\n",
    "                meta[key][accession] = header[position] if type(position) == int else '' if re.search('.*' + position + '([^|]+).*', entry.description) == None else re.search('.*' + position + '([^|]+)|.*', entry.description)[1]    \n",
    "            except:\n",
    "                meta[key][accession] = ''\n",
    "         \n",
    "    framemeta = pd.DataFrame(meta)\n",
    "    \n",
    "    return(framemeta)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52cc146b-dc7d-479b-8d50-544b809510d9",
   "metadata": {},
   "source": [
    "### Alignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "59de8431-816b-404e-9a07-2fc87b8d8192",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Fasta(data=''):\n",
    "    bundle = {}\n",
    "    bundle['application/vnd.fasta.fasta'] = data\n",
    "    bundle['text/plain'] = data\n",
    "    display(bundle, raw=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0702961c-cc40-44b1-a84a-8c4cbac60908",
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_seq(accession):\n",
    "    rec = record_dict[accession]\n",
    "    #name = 'cluster_' + str(framecentroid.loc[accession].item())\n",
    "    name = accession\n",
    "    rec.id = name\n",
    "    rec.name = name\n",
    "    rec.description = name\n",
    "    return(rec)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eced3650-4720-481e-bac1-0788d897289c",
   "metadata": {},
   "source": [
    "- needs some kind of error correction e.g. when only 4 sequences 60 clusters are impossible"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "784f0866-79db-4c34-ad4f-6b0f2c927248",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Main Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92ba42cb-c330-479b-a899-905bf692ed25",
   "metadata": {},
   "source": [
    "### Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "778e7ce5-45cb-4b59-95bd-d77cf16e7238",
   "metadata": {},
   "outputs": [],
   "source": [
    "name = 'influenza_segment_8'\n",
    "k = 7\n",
    "split = '|'\n",
    "quality = {\n",
    "    'pass': 8,\n",
    "    '8': 2\n",
    "}\n",
    "identifier = 0\n",
    "variable = 0\n",
    "minclust = 2\n",
    "sample = 1\n",
    "numclust = 60\n",
    "ncomp = 50\n",
    "procs = 10\n",
    "state = 1.0\n",
    "alpha = 0.0\n",
    "beta = 0.0\n",
    "init = 0.0\n",
    "preprocess = False\n",
    "infile = 'A.fasta'\n",
    "outdir = 'Result_Segment_8'\n",
    "columns = {\n",
    "    'strain': 1,\n",
    "    'segment': 2,\n",
    "    'protein': 3,\n",
    "    'type': 4,\n",
    "    'subtype': 5,\n",
    "    'year': 6,\n",
    "    'host': 7,\n",
    "    'pass': 8,\n",
    "    'season': 9,\n",
    "    'country': 10,\n",
    "    'state': 11\n",
    "}\n",
    "change = {\n",
    "    'subtype': {\n",
    "        'H': '[H][0-9]+',\n",
    "        'N': '[N][0-9]+'\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "931502fa-eb93-4e0a-bc5c-e98759a9fe26",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(outdir):\n",
    "    os.makedirs(outdir)\n",
    "\n",
    "outfolder = os.path.abspath(outdir)\n",
    "\n",
    "if not outfolder.endswith('/'):\n",
    "    outfolder += '/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "46096a2e-2cdf-4148-b20c-e58b5588269d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculation: 100%|██████████████████████▉| 54331/54332 [03:00<00:00, 300.50it/s]\n"
     ]
    }
   ],
   "source": [
    "vectors = Vectors(k = k, identifier = identifier, split = split, quality = quality, variable = variable, state = state, alpha = alpha, beta = beta, init = init, procs = procs, preprocess = preprocess)\n",
    "index, matrixl1 = vectors.calculateFrequence(infile = infile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5a948291-b4d2-4588-9246-763dcea8a7c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components = 200)\n",
    "matrixcumul = pca.fit_transform(matrixl1)\n",
    "varcumul = np.cumsum(pca.explained_variance_ratio_)\n",
    "compcumul = range(1, varcumul.shape[0] + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7c288ad7-6d6c-47b8-b4a8-85fe70f021b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "if ncomp:\n",
    "    matrixpca = matrixcumul[:,:ncomp]\n",
    "    variance = pca.explained_variance_ratio_[:ncomp].sum()\n",
    "else:\n",
    "    matrixpca = matrixcumul[:,:50]\n",
    "    variance = pca.explained_variance_ratio_[:50].sum()\n",
    "    ncomp = matrixpca.shape[1]\n",
    "#implement kneedle here also"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "43bbbf92-15b3-429d-8eb9-9c896282a225",
   "metadata": {},
   "outputs": [],
   "source": [
    "framepca = pd.DataFrame({'components':compcumul, 'variance':varcumul})\n",
    "framepca.set_index('components', inplace = True)\n",
    "framepca.to_csv(outfolder + 'pca_' + name + '.csv', index=True, header=True, sep=',', mode='w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d64e8455-773b-442c-ade0-e60a1a2b093a",
   "metadata": {},
   "outputs": [],
   "source": [
    "matrixl2 = normalize(matrixpca, norm='l2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3e9a31b4-5560-4b78-ae6d-6388f24ff187",
   "metadata": {},
   "outputs": [],
   "source": [
    "hdbinit = hdbscan.HDBSCAN(min_samples = sample, min_cluster_size = minclust, gen_min_span_tree = False, metric = 'euclidean', core_dist_n_jobs = -1).fit(matrixl2)\n",
    "linklocal = hdbinit.single_linkage_tree_\n",
    "framelocal = linklocal.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7f64d4be-e194-43a8-a6d1-1822de17d252",
   "metadata": {},
   "outputs": [],
   "source": [
    "if numclust:\n",
    "    cluster, n = Cluster(linklocal, minclust, numclust) \n",
    "else:\n",
    "    a,r = knee_location(framelocal, t=10)\n",
    "    x = a[a['y_diff'] == r.max()].iloc[0].y\n",
    "    cluster = linklocal.get_clusters(cut_distance = x, min_cluster_size = minclust)\n",
    "    n = cluster.max().item()\n",
    "\n",
    "framecluster = pd.DataFrame(cluster, columns = ['cluster'], index = index)\n",
    "framecluster.index.rename('accession', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7a3ffba6-8814-4ed2-a4b2-b8d008a22e99",
   "metadata": {},
   "outputs": [],
   "source": [
    "framel2 = pd.DataFrame(matrixl2, index = index)\n",
    "framecentroid = Centroid(framecluster, framel2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0d3db667-ff37-4e59-9b8c-218e45269185",
   "metadata": {},
   "outputs": [],
   "source": [
    "unclustered = len(framecluster.query('cluster == -1'))\n",
    "clustered = len(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bceb9676-475c-4477-b639-c3e53b1ffa0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector Dimensionality:\t16384\n",
      "Unclustered Fracture:\t0.0883%\n",
      "Explained Variance:\t86.0462%\n"
     ]
    }
   ],
   "source": [
    "print(f'Vector Dimensionality:\\t{matrixl1.shape[1]}\\nUnclustered Fracture:\\t{unclustered/clustered*100:.4f}%\\nExplained Variance:\\t{variance*100:.4f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "370e9d9e-d1da-43a6-a217-659fd42a02a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "framemeta = curateFASTA(infile = infile, split = split, identifier = identifier, columns = columns)\n",
    "framemeta.index.rename('accession', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "12a73d68-c8e7-474c-837e-24512501fc62",
   "metadata": {},
   "outputs": [],
   "source": [
    "if change:\n",
    "    for key in change.keys():\n",
    "        for col in change[key].keys():\n",
    "            framemeta[col] = framemeta[key].apply(lambda x: re.search(change[key][col], x).group(0) if re.search(change[key][col], x) else np.nan).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6bf4c38f-a9fc-4e2a-91b6-b42297b8da9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "framemeta.replace('', 'NA', inplace = True)\n",
    "framemeta.replace(np.nan, 'NA', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "da55e1ea-fc9e-4f9e-bcce-6d6e18c74cb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "framemeta.to_csv(outfolder + 'meta_' + name + '.csv', index=True, header=True, sep=',', mode='w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2ef9932d-34be-4843-821f-2acd77526fc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "framecluster.to_csv(outfolder + 'cluster_' + name + '.csv', index=True, header=True, sep=',', mode='w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f059a583-5d06-41cc-92cb-b111280608b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "count = framecluster.query('cluster != -1')['cluster'].value_counts().rename('size')\n",
    "treecentroid = framecentroid.reset_index().set_index('cluster').join(count).reset_index().set_index('accession')\n",
    "treecentroid.to_csv(outfolder + 'centroids_' + name + '.csv', index=True, header=True, sep=',', mode='w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0315d821-f2c4-481f-94c3-851d0fcfe714",
   "metadata": {},
   "outputs": [],
   "source": [
    "matrixpca3d = matrixcumul[:,:3]\n",
    "matrix3d = normalize(matrixpca3d, norm='l2')\n",
    "frame3d = pd.DataFrame(matrix3d, columns = ['x', 'y', 'z'], index = index)\n",
    "frame3d.index.rename('accession', inplace=True)\n",
    "frame3d.to_csv(outfolder + 'vectors_' + name + '.csv', index=True, header=True, sep=',', mode='w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "683d96a7-4879-479f-8bfc-e8d3d29cf63e",
   "metadata": {},
   "outputs": [],
   "source": [
    "frameinfo = pd.DataFrame({'name': name, 'sequences': len(index), 'cluster': n, 'unclustered': unclustered, 'components': ncomp, 'variance': variance}, index=[0])\n",
    "frameinfo.to_csv(outfolder + 'info_' + name + '.csv', index=False, header=True, sep=',', mode='w')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15a080fa-a0cd-4869-8857-e43565679bc9",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Alignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "adf2d372-f2ee-47b2-99a8-d6adc436fa8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "record_dict = SeqIO.index(infile, \"fasta\", key_function = lambda entry: entry.split('|')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "520835a2-5874-4f9a-afa0-4853fca7ef70",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = SeqIO.write(map(change_seq, treecentroid.index.tolist()), outfolder + 'centroids_' + name + '.fasta', 'fasta')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d154e481-f1f3-4e3e-92aa-b14772a48fda",
   "metadata": {},
   "outputs": [],
   "source": [
    "in_file = outfolder + 'centroids_' + name + '.fasta'\n",
    "mafft_cline = MafftCommandline(input = in_file, thread = 16, treeout = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "056ed529-03dd-415e-bbb4-83c8905db5e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "stdout, stderr = mafft_cline()\n",
    "align = AlignIO.read(StringIO(stdout), \"fasta\")\n",
    "_ = AlignIO.write(align, outfolder + 'centroids_' + name + '.msa.fasta', 'fasta')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "314ec73e-8252-445e-b3be-f00b72a28b9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#with open(outfolder + 'centroids_' + name + '.msa.fasta', 'r') as fasta:\n",
    "#    Fasta(fasta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2e47b868-6dd2-4fb5-a90c-82c1d5d3183a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(outfolder + 'centroids_' + name + '.fasta.tree', 'r') as read:\n",
    "    update = re.sub('\\d+_(.*?)([:|\\n])', r'\\1\\2', read.read())\n",
    "with open(outfolder + 'centroids_' + name + '.fasta.tree', 'w') as write:\n",
    "    write.write(update)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1afea0f8-729c-412c-954d-e80288069d3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "raxml_cline = RaxmlCommandline(\n",
    "    sequences = outfolder + 'centroids_' + name + '.msa.fasta', \n",
    "    model = 'GTRGAMMA', \n",
    "    name = name + '.tree', \n",
    "    rapid_bootstrap_seed = 1234, \n",
    "    threads = procs, \n",
    "    num_replicates = 100, \n",
    "    algorithm = 'a', \n",
    "    parsimony_seed = 1234,\n",
    "    working_dir = outfolder\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "07ee9cf1-5f45-4dcd-a807-9e19192a80a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = glob.glob(outfolder + 'RAxML_*' + name + \".tree\")\n",
    "\n",
    "if files:\n",
    "    for f in files:\n",
    "        os.remove(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "88b4ea8b-b7b1-4624-908e-b718c3878437",
   "metadata": {},
   "outputs": [],
   "source": [
    "stdout, stderr = raxml_cline()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
